{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "911a70af",
   "metadata": {},
   "source": [
    "### **Part 2: Enhance Chatbot with Tools**\n",
    " 1. Specify tavily api key (tavily is used to search internet like google but designed for llms)\n",
    " 2. Define the tool TavilySearchResults to inovke \n",
    " 3. Rebuild the chatbot from part one with **bind_tools** added to the llm. (this tells llm how to format json get/post requests when using the tavily search api)\n",
    " 4. Add tools to a new node in the **STATEGRAPH** to create function to run tools if called \n",
    "    - ***BasicToolNode*** is a class that checks the most recent message in the ***STATE*** instance and calls tools if the message contains **tool_calls**. Langchain provides a prebuilt ***ToolNode*** class to abstract this if building from scratch is to painful\n",
    " 5. Define ***conditional edges*** to route the contorl flow from one note to another. *Conditional Edges* usually ocntain  'if' statements to route to different nodes depending on the current graph state.  These functions receive the current graph state and return a string or list of strings indicating which node(s) to call next.\n",
    "    - Note: the prebuilt *tools_condition()* method should be used in production , we define our tool router manually for instructive purposes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "182122c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import API Keys        \n",
    "_root = \"/home/zjc1002/Mounts/code/admin/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fafe9285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, json \n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from IPython.display import Image, display\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# Model speicifc functions \n",
    "from anthropic import Anthropic\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "# Custom functions\n",
    "sys.path.append(_root)\n",
    "from api_keys import _api_keys\n",
    "from sys_ops import _set_env\n",
    "\n",
    "# This internet tool requires an API key to be set in the environment variable TAVILY_API_KEY\n",
    "_set_env(\"TAVILY_API_KEY\"\n",
    "         ,value =  _api_keys['TAVILY_API_KEY'])\n",
    "\n",
    "#SET ANTHROPIC API KEY ENV VAR\n",
    "_set_env(\"ANTHROPIC_API_KEY\"\n",
    "         ,value =  _api_keys['ANTHROPIC_API_KEY'])\n",
    "\n",
    "# Specifcy Anthropic model to use \n",
    "_model_id = \"claude-3-haiku-20240307\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f441da",
   "metadata": {},
   "source": [
    "### Create/Define Tools to use in graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0585feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINE THE TOOL \n",
    "tool = TavilySearchResults(max_results=1)\n",
    "tools = [tool]\n",
    "\n",
    "# The tool will return a dictionary with the results\n",
    "#print(f\"<b>THIS IS A TEST TO SHOW FORMAT OF TAVILY RESPONSE:</b> \\n\\n{tool.invoke('who is zachary carideo?')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4a0d86",
   "metadata": {},
   "source": [
    "### Define the State Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "226a005e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7f5ed9816b90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The StateGraph is a way to define the state of the application and the nodes that will be used to process the state\n",
    "# Define the State class that represents the current state of the conversation\n",
    "class State(TypedDict):\n",
    "    \"\"\"\n",
    "     The State Class contains a messages field that holds the conversation history\n",
    "     The Annotated type hint indicates that this field uses the add_messages function \n",
    "     to properly append new messages to the existing conversation\n",
    "    \"\"\"\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "class ConifgSchema(TypedDict):\n",
    "    use_tavily: bool \n",
    "\n",
    "# NOTE: You can use the  config to pass parameters into the tools you are calling(here Tavily Search parameters)\n",
    "def chatbot(state: State\n",
    "            , config: RunnableConfig\n",
    "            )-> dict:\n",
    "    \"\"\"\n",
    "    The chatbot node function takes the current State as input and returns a dictionary containing\n",
    "    an updated messages list under the key \"messages\".\n",
    "    NOTE: This is the basic pattern for all LangGraph node functions.\n",
    "    \"\"\"\n",
    "\n",
    "    # The state is a dictionary that contains the current state of the conversation\n",
    "    # The config is a dictionary that contains the parameters for the LLM\n",
    "    _use_internet = config['configurable'].get(\"use_tavily\",False)\n",
    "    _message = llm_with_tools.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [_message]}\n",
    "\n",
    "\n",
    "# Add a BasicToolNode that checks the most recent message in the state and calls tools if the message contains tool_calls. \n",
    "# It relies on the LLM's tool_calling support, which is available in Anthropic, OpenAI, Google Gemini, and a number of other LLM providers.\n",
    "class BasicToolNode: \n",
    "\n",
    "    \"\"\"A node that runs the tools requested in the  last AIMessage\"\"\"\n",
    "\n",
    "    def __init__(self\n",
    "                 ,tools: list\n",
    "                 ) -> None: \n",
    "        \n",
    "        self.tools_by_name = {t.name: t for t in tools}\n",
    "    \n",
    "    def __call__(self,inputs: dict): \n",
    "\n",
    "        # Check the most recent message in the state and call tools if the message contains tool_calls\n",
    "        # check if the last message is a tool call\n",
    "        # if the last message is a tool call, run the tools\n",
    "        # if the last message is not a tool call, return the inputs\n",
    "        #Note: in python empty collections(like []) are considered False, while non-empty collections are considered True\n",
    "        if messages := inputs.get(\"messages\",[]): \n",
    "            message = messages[-1]\n",
    "            print(isinstance(message, ToolMessage))\n",
    "        else: \n",
    "            raise ValueError('No Messages Found in inputs')\n",
    "\n",
    "\n",
    "        outputs = []\n",
    "        for tool_call in message.tool_calls: \n",
    "            \n",
    "            #run the tool and get the result\n",
    "            print(f\"Running tool: {tool_call['name']}\")\n",
    "            print(f\"Tool call args: {tool_call['args']}\")\n",
    "\n",
    "            tool_result = self.tools_by_name[tool_call['name']].invoke(tool_call['args']\n",
    "                                                                       )\n",
    "            #add the result to the outputs list\n",
    "            outputs.append(\n",
    "                ToolMessage(content=json.dumps(tool_result),\n",
    "                            name = tool_call['name'], \n",
    "                            tool_call_id = tool_call[\"id\"]\n",
    "                            )\n",
    "            )\n",
    "\n",
    "        return {'messages': outputs}\n",
    "\n",
    "\n",
    "#BUILD IT \n",
    "\n",
    "#use the custom State to define how the Stategraph operates\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "#select the model from ANRTHROPIC you want to use as your chatbot\n",
    "llm = ChatAnthropic(model=_model_id)\n",
    "\n",
    "# ADD TOOLS TO THE LLM \n",
    "# Tell the LLM which tools it can call\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# Add the chatbot node to the graph\n",
    "# The chatbot node is a function that takes the current state and returns a new state\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "# Add the BasicToolNode to the graph\n",
    "# The BasicToolNode is a node that runs the tools requested in the last AIMessage\n",
    "tool_node = BasicToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a33c1b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANgAAAD5CAIAAADKsmwpAAAAAXNSR0IArs4c6QAAIABJREFUeJztnXd8U1Xj/8/NXk26d0sXXbRllFlUNsLDqAVBEH+KIigUAdlDFLAgjygKiAuUCgVZDxQFZE+ZljJaWrr3Ttuk2fP+/gjfgiEtBXpzTprzfvFHmntzzqfNmzvOPYMgSRJgMLChwQ6AwQAsIgYVsIgYJMAiYpAAi4hBAiwiBgkYsAM8DxqVob5Sq5QZlDK9Xk/qtTbQAsXm0hgsgufA4AnpHn4c2HGQw5ZEVDTp8tIVhZnypnqdgzOT50DnOTCEzkxgC02hRgOoKdYoZQomm1b6QBkYxQ+K5gdFC2DnQgXCJhq0jQby6p/14kqNizcrKErgE8KFneiFUCsNRZmK8jxlZaE6brRL5+4OsBPBxwZEvH9deuFAXdwYl+4DnWBnaWea6nVXj9ZrlIbh/8+TK6DDjgMT1EW8cKCWw6P1HeUKOwiFiKs0qVsrRrzj6duZBzsLNJAW8XRKjWcgJ7q/CHYQa3B4a8XLCa6u3mzYQeCAroip31eEdBNExdmFhSYOby2P7u8Y0s0e72AQbUe8nFoXEMm3KwsBAAmJvtf/qm+s0cIOAgEURcxJlzGYtG4DHWEHgcCUpf7nD9Qie5qiDhRFvHigrsdge7QQAEAQREAk/+qf9bCDWBvkRLx1pjGqv5DNtd+2jB6DnbJuNKkVBthBrApaIpIkWZqjjBvdkRtr2sIr49zuXJTATmFV0BKxMEPB5qIVCQr+YbzMq1LYKawKWt96UaYiMIpv5UqXLFny559/PscHhw4dWllZSUEiwBXQHV1ZVcUqKgpHE7RElNTpgqKtLWJ2dvZzfKq6uloiofDsGdpTUJarpK581EBIRLXC0Firpe42JTU1deLEif379x8yZMiiRYtqamoAAD179qysrFy9evXAgQMBAAaD4ccff3zttdfi4uJGjhy5fv16lerhYWno0KF79uyZM2dOv379Ll++PHr0aADA2LFjFyxYQEVavpAhLrenBkUSGcSV6t3rSygqPD09PTY29tChQ2VlZRkZGe+///7UqVNJkqypqYmNjd27d69EIiFJcufOnX369Dl58mRJScm1a9dGjBixYcMGUwmvvvrq+PHjN23adPfuXZVKderUqdjY2OzsbLlcTkXgqiLV/m9KqSgZTRDqj6hoMvCFVB0OCwoK2Gz2mDFjGAyGr6/v+vXrq6qqAAAikQgAwOPxTC9GjhzZr1+/kJAQAIC/v//w4cOvXLliKoEgCA6HM2fOHNOPfD4fACAUCk0v2h2+iK6Q2lELDkIikkaSRdktc8+ePQmCeP/99+Pj4/v06ePt7e3i4vLkbo6OjseOHUtKSqqtrdXr9Uqlksd71CMmJiaGonhPQmcQLA5CF05Ug9CvyhMypHU6igoPCAjYsWOHr6/vli1bxo4dO3Xq1MzMzCd327Bhw/bt2ydOnLht27Y9e/YkJCQ8vlUgsF53BLlET2cQVqsOOgiJyBfSFU0Unow6d+6clJR0+vTpn376iU6nz5s3T6v9192AwWA4cuTIO++885///MfHx8fV1VUul1OXp3UovVBBEIRE5DkwnD2ZRiMlz/szMzPv3bsHAKDT6bGxsTNnzpRIJPX1Dx/pmjoZGI1Gg8FgulgEACgUikuXLrXe/4C63gkapcHNz476JiIkIgCAw6MXZiioKPnq1avz588/e/ZseXl5Tk7O3r17vby8PD092Ww2m81OT0/PyckhCCIsLOzo0aPl5eV5eXnz5s3r379/U1NTcXGxXq83K1AoFAIA/v7778LCQioC59ySeQXY9tCcZwItEQO68IvvUyLie++9l5CQ8O23377++uuJiYkkSW7evJkgCADA1KlTz5w5M2vWLJVK9emnnxoMhokTJy5btmzSpEmJiYmenp5vv/12bW2tWYERERFxcXHffPPNl19+2e5pDXqyIl/lH25HIwfQ6qGtkutPpdTEf+gDOwhkiu7Ly3JVryS4wQ5iPdA6InIFDCcP1l0763jyJFf/qLe33ukItSOa6D/G9aelBV0HWO4YazAYhgwZYnGTVqtlsVgWNwUGBu7YsaNdYz4iOTk5OTnZ4iaBQNDSfXdERMQPP/xgcdODtCZ3P46zh+XfpaOC1qnZxJ2LEoIgu75ieRSzTCaz+L5Go2GxWKbLPjNoNBpFzz9M9Zo1AzWj0+mYTKbFTXQ6/fGm8sc5ur1ywOtuDo6WP9hRQVFE05fRpa/I+l3CoGO3vzha14jNjH7f+9KhuvpqDewgVuXcvlrPAI4dWojuEdH06Hnf12WvjHPzDraL5rTz+2t9O3Ptdh4cRI+IAACCRkxa5H/teH32zSbYWajFaCAPb61w9mTZrYVIHxGbuXpUXJqtjBvj2iEbeP851ZCTJhs4wc2eJ76xDREBAHUVmqt/ivlChncwNzCKz+XbfG+A2jJ1aY4y7VRjt4GOvUc402h21NHGIrYhoonyPGVOmqwoU+Hmxxa5MvlCBl/I4AnpRiPsZG2ATgBpg04hNZCAfPCPjC9khHTlx7ziyGShe3VkTWxJxGaqilTiCq2iSa9o0tMIQilvz85jSqWypKQkIiKiHcsEADg4MUmS5IvoDs5M32AuX4TcowS42KSIlJKdnb127dqUlBTYQewLfF7AIAEWEYMEWERzCILw9/eHncLuwCKaQ5JkaWkp7BR2BxbRAtYcrYcxgUW0AMTBe3YLFtEcgiBcXe19gkbrg0U0hyRJsVgMO4XdgUU0h0ajBQYGwk5hd2ARzTEajUVFRbBT2B1YRAwSYBHNIQiiedYRjNXAIppDkqRUal8TqaMAFtECjo52utwQRLCIFqB0lnaMRbCIGCTAIppDEISPj73PAmV9sIjmkCRZUVEBO4XdgUXEIAEW0RyCIDp16gQ7hd2BRTSHJMmSkhLYKewOLCIGCbCI5uDeN1DAIpqDe99AAYuIQQIsojl4OCkUsIjm4OGkUMAiYpAAi2gBPK7Z+mARLYDHNVsfLKI5NBrN19cXdgq7A4tojtFoLC8vh53C7sAiYpAAi2gOQRDOzs6wU9gdWERzSJJsaGiAncLuwCKaQ6PRAgICYKewO7CI5hiNxuLiYtgp7A4sojn4iAgFLKI5+IgIBSyiOTQazd3dHXYKuwMv+POQyZMny+VygiC0Wq1cLndyciIIQqPRnDx5EnY0uwAfER8ycuTI2trayspKsVisVqurqqoqKysdHOx33Vorg0V8yKRJk/z8/B5/hyCIAQMGwEtkX2ARH8JisV577TU6/dECvP7+/q+//jrUUHYEFvEREydObJ71hiCIQYMGeXl5wQ5lL2ARH8FiscaPH286KPr7+0+YMAF2IjsCi/gvJk6c6O3tbTocenh4wI5jR9jA8tU6jbGhRquUGkjCGtXFD5tx4cKFl3qML8xUWKE6Gg04ebBELkwr1IUyqLcjXj1an39HzuLQBI5MowHpqM+HwIlR9kAhcmP1GubkE8KFHQcaSIt4dl8tm0PvOtAFdhDK0agNp3dWDprg5hnAgZ0FDuheI148VMfhMezBQgAAm0MfPcPv9O6axhot7CxwQFRESZ22sVob84p99ZTuO8b9n9ONsFPAAVERG6q1NDqi2ahD5MosfaCEnQIOiH7Zcone0Z0FO4W14fIZfCFDozbCDgIBREUkSaDTonsXRR1N9VoaYZVmKsRAVESMvYFFxCABFhGDBFhEDBJgETFIgEXEIAEWEYMEWEQMEmARMUiARcQgARYRgwQdX8QJb4z85dfvX6SEz1YtXrBwZvslwlig44v4fKxaveTEyT9fpITDqfvXf7mq3QJ1dLCIlsnNzYZegl1hA6P42ohOp0v+7adTp4/J5bKQkLAPps+Jiupq2kSj0X7bue3IHwfkcln37r2WLl7l5OQMAGhsbPjhp2/T02/KZE1ubh7jXntj3LhJAIBBQ3oCAP775eqt33/955ELpvH2x/86smvX9voGcVBgyPz5K0I7h5sKP3Y8df+BlMrKci6X16d33MwPP3Z2dpk3f8bdu+kAgJMnj545dePxCSQwFuk4R8Qffvzm2PHUWTPnf/vNNh8fv8VLZ1dWVZg2nb9wWipt/GLdpk9WrM3Kupf820+m97/8ak3W/XsrV6zb/vPvb06euvWHjX9fuQAA2L/3OADgo9mLUnYdMe1ZUlp09uyJZUvXbPjvVq1O+8nK+TqdDgBw6tSxr75OGj5s1K/b961ZtSE378Gy5XNJkkxaszG0c/jgQcNTD53BFraFDnJEVCqVx46nfjBj7qCBwwAACz5eoVIqKyrKvL18AAB8vmDOR4sBAGGhEZf/Pp+dnWn6VOKsBTQazbSPn1+nI0cOpKVdf6n/QKFQBADg8Xgioci0p0TS+Mv2fUIHIQBg5ocfL14y+87dW7169j1wcHf//gOmvPmuqYSPZi9atDgxM/NudHQ3OoPBZLFEIkeofxiboYOIWFJapNVqI8K7mH5kMpmrV33ZvLVLZEzzaydH5yxlhuk1l8Pdszf5zp00qVRiNBplsiYfH78nygYAgKDAEJOFAIDIiGgAQGlpcfduPQsK8wYNGt68W1hYJAAgvyA3OrobNb9oh6WDiCiXywAAbLblQcFc7qOB6wTxsCe+Xq9fvHS2wWCYnbjQ3y+ATqd/8umClsrn8x8tE2kqTaNRq9QqkiR5PH7zJh6XBwBQqex0ANSL0EFENJ0BlcpnmCQkOzuzsDB/0zfbYmK6m96RShq9PL0t7qxSq5pfK5VKAACHw+VyuDQa7fFKFUqFmbWYNtJBblZ8vP04HM7de+mmH41G49yPp588ebSVj2i0GgCA8P+uAu/fv1dVXfn4vBePvy4uLmhesjQnNwsAEBAQxGAwQoJDMzLvNO+Wdf9e8wnarARM63QQEfl8/sgRY3fv+fXUqWM5udkbv1mXm5sd1eqFWkhwKIvFOnR4b329+J+065u3fNmrZ9+y8pLGxgY2m81ms+/eS8/Lz9Hr9QAAHo+/4as1xcWFhYX523/Z6unhFRPdHQAwYcJb16//vf9ASnV11e07aVu2ftW1a4/wsEgAgIPAIT8/Jy8/B+vYFjrIqRkA8MGMuQSN9uPPm1QqZWBgyBdrN/l4t7baraOj0+JFn23f/t2p08dCQyOWLF5VJ679PGnZ/IUf7vhl/+RJU/fu++3atcspu1L1Bn2XyJjY2D5Ll8+prxd37hye9PlGBoMBABg6ZIRGo95/IGXb9u/4fMFL/Qd+8MFcU/kJCZO+WP/pnLnT/jxywbQzphUQnYTp7iWJuErfe4Qr7CDWZs+6gvfWBDHZdje0uYOcmjG2DhYRgwRYRAwSYBExSIBFxCABFhGDBFhEDBJgETFIgEXEIAEWEYMEWEQMEmARMUiARcQgAaIisjgEi4toNkpx8WETdjnoD9Ev29GdVZlvdyM/Gms1GqWRwbC7PmDoiujpz6HTgU5rX0vf1JaqQ7vb6XgXREUkaETcGJczKZWwg1iP0gfygjtNvV61r+UHm0G0h7aJ2nJN6taK2OEuIleWgyMT4aQvRH2VWtaoK86UvzHfl6DZ43kZdREBAGql4daZxqoitVph0OseRtVqtXQ6naKpPIwGg1an43CstG6yjmgUOQrDu7vEvGzfc0KQtkZJScm3335LXfmrVq0aPHjwtWvXqKvicWQy2fLly61TF8qgfkR8HKlUWl1d7enpKRKJKKoiKyvrk08+KS0tjYuL27x5M0W1WGTfvn0xMTERERHWrBQdEL1ZeRKxWJyQkBAYGEidhQCA33//vbS0FACQm5t75coV6ip6klGjRq1du1YikVizUnSwDRFra2tLS0vPnTvHYlG4iHN2dnZ6+sO5IsRi8Z49e6ir60kEAkFKSgoAICMjo7y83JpVo4ANiDh//nySJHv06EF1Rbt3766pqWn+MSsry8oHRQCAo6NjSEhIYmJiXV2dlauGC9IikiR569at+Ph4Dw8PquvKyspqPhyakEqlpkOUleFyuUeOHNFqtVKp1DThkz2Aroi3b99WKBTR0dEDBgywQnU7d+6sqakxGo3N93EAgAcPHlihaov4+Pjw+fxXX33V7L9HhwXqPXuLZGRkTJs2DUrVWVlZU6ZMgVK1RXbs2AE7gjVA9IjY2Ni4fft2WLV36tQJVtVPMnXqVADAihUrxGIx7CwUgpyIH3/8MQDg5ZdfhhVApVLV1tbCqr0lFi5c+Nlnn8FOQSFoiXjgwIGEhAS4GVQqlZubG9wMT+Lk5LR161YAwNmzZ2FnoQS0RBw0aNArr7wCN4NYLLbag+bnwMPDY8qUKbBTtD9IiKjVagcOHAgAcHWFPyGiVCr18fGBnaJFoqKiVq5cKZFIZDIZ7CztCRIiJicnX7hwAXaKhxQUFFih2fJFCA8Pd3R0TE9PP3fuHOws7QZkEQ0GQ01NzYwZM+DGMCMgIAB2hKczYMCAv/76SyqVwg7SPsDsfdPU1BQfH3/+/HlYASzSq1evGzdu0GhInCueikQiqa6uDg8Phx3kRYH25zY9vkPNwgcPHvTr189WLDQ9m+bxeJ9++insIC8KtL94VlaW6QYFKa5evRoWFgY7xbPh7+/fp08fW+8/BkfEyZMnM5nM/1uMDCEuX74MsS39uRk1ahSNRmtoaIAd5PmBIOKtW7c2btwYGhpq/apbRyqVCoXCmJiYNuyLHEKh8ObNmytWrIAd5Dmx9s2KXq8nCALNJYx//fVXlUqVmJgIO8jzU1ZWJpVKo6KiYAd5Zqx6RMzOzp46dSqaFgIADh06NG7cONgpXgg/P7+AgACF4hkWx0QEq4p4/vz5H3/80Zo1tp0rV6706tXLy8sLdpAXRSAQLF269OrVq7CDPBu2NIqPUt544421a9eGhITADtI+HDp0aNSoUWw2G3aQtmKlI6JMJlu8eLF16noOTp8+HRgY2GEsBACMGzfOhiy03uqkW7Zs6dOnj3Xqeg42bdqUnJwMO0U789133/H5/HfffRd2kDZhjVOzwWAQi8XI9iTYvHmzSCR65513YAdpfxYtWrR8+XInJyfYQZ6ONUTU6/UkSTKZTKoreg6Ki4tXrly5a9cu2EHsHWtcI06bNi0nJ8cKFT0H8+bNW7duHewUFHLy5EmbGCJNuYhSqZTNZqPZxJqUlPTOO+/4+fnBDkIhfD4/KSkJdoqnY7/NN2fPnr1x48by5cthB6GctLS08PBwgQDpuWgpF1EikTAYDNT+CqWlpXPnzj18+DDsIJiHUH5qXr9+/bVr16iu5VmZOHHi/v37YaewEiqV6s0334Sd4ilQLqKDgwNqPe+XLVuWnJyM5l08FXC5XBcXF8Qf+tndNeKiRYtGjhw5ePBg2EGsilqt1mq1QqEQdpAWofyIWF5ertfrqa6ljWzYsCE2NtbeLAQAcDgclC20hohLlizJz8+nupa2cPDgQQ8Pj0mTJsEOAodx48ZVV1fDTtEilIsYGRlpMBioruWp7Nu3r7Cw8O2334YdBBo9evTIzc2FnaJF7OIa8Y8//rh9+3bHnsTI1qG8941pdJmjI7RFRE6cOPHPP/98/vnnsAIgwsNpCFEdKUt5rLS0tC+++ILqWlri4MGDly5dwhaa1kl46623YKdoEcpPzbW1tePHjxeJRDKZTCaTWXMi3pSUFAcHh/j4eKvViDJNTU3jx48/ffo07CCWoUrEGTNm3Lt3z6zhxtXVdd26dVZYHwAAcOTIkfT09NWrV1uhLsyLQ9Wp+eeff36yVwubzbbOqOFdu3YVFBRgC82oqalBoQXDIhReI86ePdvb27v5R5IkIyMjGQzKb49SUlLq6+vnz59PdUU2x4cfflhRUQE7hWUoFHHAgAGjR4/m8/mmHzkcjhWGrWzcuJFGo82bN4/qimwRNput0Whgp7AMtXfNM2bM6N27t6nJwMnJKTo6mtLq1qxZ4+HhgX5PE1gkJycHBwfDTmEZyptv1q1bFxwcbDQaRSIRpX+FpUuXdu3atUPOL91eqFQqZK8R23TXrNcZVXLjc9eRn5+/bt26/v37T5s27bkLaZ3PPv1s5NiBw4YNo6j8jsGcOXOmT59O9Xnp+XiKiNk3m+5dljZUa7kCRCesMd0GsfjGxkoyMIrfY7CjVyAXdiK06NGjB0EQJEk2zwNIkmRoaOjevXthR3tEa/ewN081iCt1L4/zdHC2gT6kJElK63QX/lcTN8qlUwQPdhyECAsLy8nJefzhnkAgmD59OtRQ5rR4jXjjRIO0Tv9ygodNWAgAIAjC0Z01errfjRMNJdn2sqhnW5g0aRKX+6+zRKdOnYYMGQIvkQUsi9hYqxVXaPqOdrd6nnZgyBSv2+cbYadAiPj4+MdXjuHxeAjOQ2JZRHGFhiSRm1e4jbDYdEmdrqlBBzsIQkyZMoXFYpleBwUFDRo0CHYicyyLKJca3PzQXQbsqfiF8RtrsYiPiI+P9/X1NY23Ny13ihqWRdRpjDr187fXQEcu0ZGGjt/h95mYMmUKk8kMCgpCcDEH601Lh3kmSh4oZI16ZZNBqzKqVe3TBM0HfQd2+ahLly5nfq9pnwKFDKOB5AsZfCHdM5Dj4PRCN7VYRITISWvKva0oyVJ4hwp1OpLOoNOZDEBrt1aL3v1GAQBk7dSioFATeq3OWKoljWTTITGXTw/pxu8SJxSInicwFhEJ8m7LLqfWO3nz6Wx+l2FuCK5A0zrunYFKpikrUmbdrAyM5L30mguD+WxPj7GIkDEYyGO/VCtkwLerF4trw18H14HNdWC7Bjo1lEl/XlY0cIJbZJ9nGEltw795B6C2TH3g2/LgPt5CP1ua77p1nP1Ezn6ijGt1dRWaAePc2vgpRMd02QPSeu3xHbVdhgZyHDqOhc14hLnVi2mXU+vbuD8WEQ7VJerU76sDevm0YV9bxdnPsbYa/PVbm6aXwCJCQK8zHtpS0alnR7bQhEsnR6WClnbm6U9csYgQOPZrTXDfjm+hCZdAl5IcTVneU1ZlwyJam/vXpAoFwebbRp+mdoHnKrz4v6dcLGIRrc2VPxvcg5xhp7AqXCGbxmDk3Za1sg9CIn62avGChTNhp6CWzKtSl04ODDai3d3vZp5duLKPQiFp95JdAp3vX5e3skO7iXg4df/6L1e1V2kdlQdpcjbfhrs1PTdsHrOhWttYo21ph3YTMTc3u72K6qjoNMa6MrXAxU6H1PBdeYUZLR4U2+fJyrz5M+7eTQcAnDx59OefdncOCcvIuLPtl+9yc7MJgogIj5o+/aOI8C6mnY8dT91/IKWyspzL5fXpHTfzw4+dnV3MCjx2PPXg//ZUVVWw2ZyuMT1mJy50d0d0Kb+2U5ytcA10oK782/dOXbyyp6auiM3mdY8ePnLoTBaLAwDYuXc5QYCwzv3OX9opldW5u3ZKGL2wk180AMBg0B85/k36vROk0RgZ9lJIUE/q4jm48apLW7xMbJ8jYtKajaGdwwcPGp566ExQYEhZWcnCxbPcXN23bkn+bvMOLo+3cNHM2toaAMCpU8e++jpp+LBRv27ft2bVhty8B8uWzzUbSXjv3u2vvk4aP27yL9v3fbFuk7RJsvrzpe2SEy7SOr1BR1Vvhsysi7sPrAwN6b0gMeWNhJX37p87+MfD2QDpdEZRyd3SsvvzZu1cteQEjyfad+jhWlTnLv12Iy117Mh5H8/aGRjQ7czFXymKBwBgshlVhaqWtraPiAKBgM5gMFkskciRTqcf+eMgl8tbtnRNcHDn4ODOK5Yl6fX6k6eOAgAOHNzdv/+AKW++6+fXqVu32I9mL8rNe5CZeffx0oqKC9hs9ohXx/h4+0ZGRH22cn3irAXtkhMucomeutuUc5d3BgX0+M+wWa4ufhGhcaOGJ6bfPSGRPux6qNWqxo6cx2ZxWSxOj5gRteJirVYNALh196+oyAG9e4xxdfGL6z0+NJjCOWGYHIZa0WLfSkrumnPzskM7hzfPt8Tj8fz8OhUU5Or1+oLCvMiIRwO8w8IiAQD5Bf+a27l7t54EQcyZ9/7RY4erqiudnV0iI1Bcyu9ZUcoNFIloNBrLK7NDQ3o3vxMU0AMAUFX9cBp9Vxc/02kaAMDjCgEASlWTXq8T15f5+UQ2f8rftwsV8Zph8+mKJstDOCjpfaNUKlycXR9/h8fjK5UKlVpFkiSPx3/0PpcHAFCp/tVX098/4LvNO37f99vP27bINq6NiIianbiwA7hI3ZSoOp3aaDScOrft9PlfHn+/SSY2vWAwnuxXQWq1KgAA87FNbDa148FJA9lSV0tKROTzBQrFv+6PFAq5i7Mrl8Ol0WhK5aOnPQqlwrS/WQnBwZ0/WZ5kMBgyMu78suP75Svm7d97vHkcmo0iENHr6iiZeobJ5NDpjJf6vtEnduy/auS31nLOZHEAACrNo29KpWqtzfkFIUlSqzbyHCwr156n5uZ7jrDQyJzcbJ3u4UFYJpeVlhaHh3dhMBghwaEZmXeaP5J1/17zCbqZ7OzM+/fvAQDodHq3brHvvTtTKpU0NLS1QxGyCBwZei0lItJoNB+v8EZJlbtbgOmfs5MPjcbg8VrrmspksJwcvaqq85rfyS24SUU8E3qNgcNv8cqk3UR0EDjk5+fk5edIpZL4+AkajfrLr9aUlZUUFuYnrV3B5wteHT4aADBhwlvXr/+9/0BKdXXV7TtpW7Z+1bVrj/B/i3jj5tUVK+dfvHS2orI8Lz/n0KG9nh5eHh6e7RUVFo5uTAadqrGRA196KyPr/LlLv9XWlVRU5uw5+NnW7TPU6qd0NegePTwz6+L1tNSq6vyLV3ZXVlG4EItWpfcKarENtd1OzQkJk75Y/+mcudNWr9rQu1e/Df/d+vP2Le/PmEyn06Ojun3z9U+Ojk4AgKFDRmg06v0HUrZt/47PF7zUf+AHH8w1K+qtKe/p9boff/xWXF/H5wuiorqu/2KzzQ3jeJKALvwTv1W7Brm2Yd9nJqbLoMnjV5+/vPPk2Z85HEGAf8zM977ncPitf2qVi9dZAAADPElEQVTY4PcVSsnRE5uNpDEitP+o4bN37ltmJCn536IQKzrHtNgF2PJsYDdPNmjVoOtAW302f+73yq4viwK6POVrsD6Ht1YyhA4OrvY4R1TB1bLX5/mIXCx3O0Ko04M9EN5boJEjOnkwpajlWldfdksW4sFT1iail/Da0WKhh4DFtfyVZGZf2nvI8mIIfK5IoZJa3NQ39rXRIz5qr5BFJXd+SbH8BMFoNNAIGrB0mdSv17hRwxNbKlNc2PDSmNZWH8MiWpuXX3P552yjdxfLM62FBveeP2uXxU1arbq5UdoMNrs9L0J8vSNayqDTaeh0psV11FrJoGhUM5lkQGRrIbGI1qZzd4e8Owq1TGNx8B6LxXFmeVv6nPVgMtnOTu2ZQd0oGzThKbdo+BoRAv9517PwZqXRaBfTRNXk1oV157o/bXI5LCIcJi/2L7xeDjsF5dTk1bt50aLiRE/dE4sIByd31ptLfPL+LjXobXj6v9apK6gPjmQOntimeYexiNDgCZhvLPDN+7tU0dhiLz0bxag3VmRWB4Qyeg51auNHsIgwETozP/xvMNOoKL9bpWrqIO2LdUWNOZdKXxrl2Gv4MzwQwXfN8Bn+lkdZrvLSYTFbwKaxWEI3PrLD/FpBXq+Si5VNtfKurzhOmPXMS4xhEZHAL5Q3ZYl/SZYi946i8GaFkxdXqzYyWAw6i0HQEH3ITqPTdCqtQWcApLGxSuXux4mM5Uf2DXjWmRFNYBERolMkv1MkHwBQU6qWNeqVTXq10qhRIrp6HldAEjQGX8jmCRlegZ5M1gtd5mERUcTDn+PhDzuEdbEsIotDGAGiZ4S2wHdk0ug2nN8OsXw4dXBi1pXYcJtCabbc2dO2xxXYG5ZFdPdj224/VJVc7+rDFjjiqw5bosUjok8I59L/2jTXJ2qcSansNayt7agYRGhtveb716R5d+RdB7g4ebDoDNSbvtVKQ5NYe+VI7Yi3Pdz97XGiI5vmKQuHF91X3LkoqS5S0xlIn6pFrsymBl1AJL/nMCcnd3x1aHs8RcRmNCqkn82TRsDho37MxrRCW0XEYCgFH0UwSIBFxCABFhGDBFhEDBJgETFIgEXEIMH/B+nyrNCjvCmYAAAAAElFTkSuQmCC",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def route_tools(\n",
    "    state: State,\n",
    "):\n",
    "    \"\"\"\n",
    "    Use in the conditional_edge to route to the ToolNode if the last message\n",
    "    has tool calls. Otherwise, route to the end.\n",
    "    \"\"\"\n",
    "\n",
    "    #get the message if it exists\n",
    "    if isinstance(state, list):\n",
    "        ai_message = state[-1]\n",
    "    elif messages := state.get(\"messages\", []):\n",
    "        ai_message = messages[-1]\n",
    "    else:\n",
    "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
    "    \n",
    "    #If message exists check if a tool has been referenced \n",
    "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "\n",
    "# The `tools_condition` function returns \"tools\" if the chatbot asks to use a tool, and \"END\" if\n",
    "# it is fine directly responding. This conditional routing defines the main agent loop.\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    route_tools,\n",
    "    # The following dictionary lets you tell the graph to interpret the condition's outputs as a specific node\n",
    "    # It defaults to the identity function, but if you\n",
    "    # want to use a node named something else apart from \"tools\",\n",
    "    # You can update the value of the dictionary to something else\n",
    "    # e.g., \"tools\": \"my_tools\"\n",
    "    {\"tools\": \"tools\"\n",
    "     , END: END},\n",
    ")\n",
    "\n",
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    print(e)\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d5e1cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: [{'id': 'toolu_01U3XkQRpm9eeaiJLZPZ18QB', 'input': {'query': 'who owns the model being used as a chatbot'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "dict_keys(['id', 'model', 'stop_reason', 'stop_sequence', 'usage', 'model_name'])\n",
      "Message ID: msg_01PgTqyqwCzPtntDByoByZPJ\n",
      "Model Used: claude-3-haiku-20240307\n",
      "Chat Stop Reason: tool_use\n",
      "Chat Stop Sequence: None\n",
      "Chat usage: {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 378, 'output_tokens': 67}\n",
      "--------------------------------------------------\n",
      "False\n",
      "Running tool: tavily_search_results_json\n",
      "Tool call args: {'query': 'who owns the model being used as a chatbot'}\n",
      "Assistant: [{\"title\": \"What does Model Ownership (in AI) mean? - Digital Fluency Guide\", \"url\": \"https://www.digitalfluency.guide/glossary/model-ownership-in-ai\", \"content\": \"The control and/or legal and financial stakes in a given AI system's underlying data. ChatGPT is based on GPT, a model owned by OpenAI.\", \"score\": 0.5689194}]\n",
      "dict_keys([])\n",
      "No response metadata found\n",
      "--------------------------------------------------\n",
      "Assistant: The search results indicate that the model being used as a chatbot, such as ChatGPT, is based on the GPT language model which is owned by the artificial intelligence company OpenAI. So the model ownership and control of the chatbot technology belongs to OpenAI.\n",
      "dict_keys(['id', 'model', 'stop_reason', 'stop_sequence', 'usage', 'model_name'])\n",
      "Message ID: msg_01JEXgrU61rv3kgeFqL7j5YK\n",
      "Model Used: claude-3-haiku-20240307\n",
      "Chat Stop Reason: end_turn\n",
      "Chat Stop Sequence: None\n",
      "Chat usage: {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 556, 'output_tokens': 62}\n",
      "--------------------------------------------------\n",
      "Assistant: I'm afraid I don't have information on who specifically owns the model being used as a chatbot in this case. As an AI assistant, I don't have direct access to details about my own development or ownership. I was created by Anthropic, but I don't have specifics beyond that. I apologize that I can't provide a more detailed answer, but I hope I've still been helpful in addressing your question to the best of my abilities.\n",
      "dict_keys(['id', 'model', 'stop_reason', 'stop_sequence', 'usage', 'model_name'])\n",
      "Message ID: msg_018VBgXBZw2boKAyF43K1zn9\n",
      "Model Used: claude-3-haiku-20240307\n",
      "Chat Stop Reason: end_turn\n",
      "Chat Stop Sequence: None\n",
      "Chat usage: {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 383, 'output_tokens': 97}\n",
      "--------------------------------------------------\n",
      "Assistant: I apologize, but without access to the internet, I do not have enough information to provide a detailed response about who Zachary Carideo is. As an AI assistant without the ability to search the web, I do not have access to biographical details or other information about this individual. I cannot give a comprehensive answer about Zachary Carideo without being able to look up relevant facts online. I'm limited in my knowledge to only what has been provided to me directly. I apologize that I cannot give you a more complete response.\n",
      "dict_keys(['id', 'model', 'stop_reason', 'stop_sequence', 'usage', 'model_name'])\n",
      "Message ID: msg_018M6PDcpM1fwUYozY1YhLY9\n",
      "Model Used: claude-3-haiku-20240307\n",
      "Chat Stop Reason: end_turn\n",
      "Chat Stop Sequence: None\n",
      "Chat usage: {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 380, 'output_tokens': 114}\n",
      "--------------------------------------------------\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def stream_graph_updates(user_input: str):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function takes the user input and streams the graph updates\n",
    "    It uses the graph to process the user input and returns the updated state\n",
    "    The graph is a StateGraph that contains the nodes and edges that define the conversation\n",
    "    \"\"\"\n",
    "\n",
    "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
    "        \n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "            print(value[\"messages\"][-1].response_metadata.keys())\n",
    "            try: \n",
    "                print(f\"Message ID: {value['messages'][-1].response_metadata['id']}\")\n",
    "                print(f\"Model Used: {value['messages'][-1].response_metadata['model']}\")\n",
    "                print(f\"Chat Stop Reason: {value['messages'][-1].response_metadata['stop_reason']}\")\n",
    "                print(f\"Chat Stop Sequence: {value['messages'][-1].response_metadata['stop_sequence']}\")\n",
    "                print(f\"Chat usage: {value['messages'][-1].response_metadata['usage']}\")\n",
    "            except:\n",
    "                print(\"No response metadata found\")\n",
    "            print(\"--------------------------------------------------\")\n",
    "\n",
    "#RUN IT \n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        # fallback if input() is not available\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \" + user_input)\n",
    "        stream_graph_updates(user_input)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03322f85",
   "metadata": {},
   "source": [
    "### CONSOLIDATED CODE TO RE-CREATE CHATBOT WITH INTERNET ACCESS USING PRECONFIGURED TOOLS and Functions to route them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99e2602c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: I apologize, but I don't have specific information about who \"Sam\" is without more context. There are many people named Sam, and without additional details or the ability to search for information, I can't provide a accurate answer about a particular Sam.\n",
      "\n",
      "Is there a specific Sam you're asking about? Do you have any more details you can share about this person, such as their full name, profession, or why you're asking about them? With more context, I might be able to help or at least guide our conversation better.\n",
      "dict_keys(['id', 'model', 'stop_reason', 'stop_sequence', 'usage', 'model_name'])\n",
      "--------------------------------------------------\n",
      "User: What do you know about LangGraph?\n",
      "Assistant: [{'text': \"To provide you with accurate and up-to-date information about LangGraph, I'll need to search for the latest details. Let me do that for you.\", 'type': 'text'}, {'id': 'toolu_01PK42kcRQkPhGxUF5kP2nn5', 'input': {'query': 'LangGraph AI tool'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "dict_keys(['id', 'model', 'stop_reason', 'stop_sequence', 'usage', 'model_name'])\n",
      "--------------------------------------------------\n",
      "Assistant: [{\"title\": \"LangGraph Quickstart - GitHub Pages\", \"url\": \"https://langchain-ai.github.io/langgraph/tutorials/introduction/\", \"content\": \"[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-9-1)Assistant: LangGraph is a library designed to help build stateful multi-agent applications using language models. It provides tools for creating workflows and state machines to coordinate multiple AI agents or language model interactions. LangGraph is built on top of LangChain, leveraging its components while adding graph-based coordination capabilities. It's particularly useful for developing more complex,\", \"score\": 0.8893851}]\n",
      "dict_keys([])\n",
      "--------------------------------------------------\n",
      "Assistant: Based on the search results, I can provide you with information about LangGraph:\n",
      "\n",
      "LangGraph is a library designed for building stateful multi-agent applications using language models. Here are the key points about LangGraph:\n",
      "\n",
      "1. Purpose: It helps developers create workflows and state machines to coordinate multiple AI agents or language model interactions.\n",
      "\n",
      "2. Foundation: LangGraph is built on top of LangChain, which means it leverages LangChain's components while adding its own unique features.\n",
      "\n",
      "3. Key Feature: The main addition that LangGraph brings is graph-based coordination capabilities. This allows for more complex and structured interactions between different AI components.\n",
      "\n",
      "4. Use Case: It's particularly useful for developing more sophisticated applications that require multiple AI agents to work together or maintain state across interactions.\n",
      "\n",
      "5. Complexity: LangGraph is designed to handle more complex scenarios than what might be possible with LangChain alone.\n",
      "\n",
      "6. Documentation: There's a quickstart guide available for those who want to learn how to use LangGraph, which suggests it's actively maintained and documented for ease of use.\n",
      "\n",
      "LangGraph represents an evolution in the tools available for AI developers, especially those working on applications that require coordinated efforts from multiple AI agents or complex stateful interactions. It's part of the growing ecosystem of tools that make advanced AI applications more accessible to developers.\n",
      "\n",
      "If you'd like more specific information about LangGraph, such as how to use it, its specific features, or examples of applications built with it, please let me know, and I can search for more detailed information.\n",
      "dict_keys(['id', 'model', 'stop_reason', 'stop_sequence', 'usage', 'model_name'])\n",
      "--------------------------------------------------\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=1)\n",
    "tools = [tool]\n",
    "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "\n",
    "#function to stream interations with chatbot \n",
    "def stream_graph_updates(user_input: str, graph):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function takes the user input and streams the graph updates\n",
    "    It uses the graph to process the user input and returns the updated state\n",
    "    The graph is a StateGraph that contains the nodes and edges that define the conversation\n",
    "    \"\"\"\n",
    "\n",
    "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
    "        \n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "            print(value[\"messages\"][-1].response_metadata.keys())\n",
    "            print(\"--------------------------------------------------\")\n",
    "\n",
    "#RUN IT \n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        stream_graph_updates(user_input, graph)\n",
    "    except:\n",
    "        # fallback if input() is not available\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \" + user_input)\n",
    "        stream_graph_updates(user_input,graph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langy3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
