{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99665ce9",
   "metadata": {},
   "source": [
    "### Pt 1 LangGraph Basics: Building basic chatbot with no memory and no tools \n",
    "- Pt 1 Tutorial: [langgraph basics](https://langchain-ai.github.io/langgraph/tutorials/introduction/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2086e85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#general \n",
    "import os, sys, getpass\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from IPython.display import Image, display\n",
    "\n",
    "#chat bot specific \n",
    "from anthropic import Anthropic\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "\n",
    "#Import API Keys        \n",
    "_root = \"/home/zjc1002/Mounts/code/admin/\"\n",
    "sys.path.append(_root)\n",
    "from api_keys import _api_keys\n",
    "\n",
    "#set Environment Variables \n",
    "def _set_env(var: str,value: str = None):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = value\n",
    "\n",
    "#SET ANTHROPIC API KEY ENV VAR\n",
    "_set_env(\"ANTHROPIC_API_KEY\"\n",
    "         ,value =  _api_keys['ANTHROPIC_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "765625b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ID: claude-3-7-sonnet-20250219\n",
      "Model ID: claude-3-5-sonnet-20241022\n",
      "Model ID: claude-3-5-haiku-20241022\n",
      "Model ID: claude-3-5-sonnet-20240620\n",
      "Model ID: claude-3-haiku-20240307\n",
      "Model ID: claude-3-opus-20240229\n",
      "Model ID: claude-3-sonnet-20240229\n",
      "Model ID: claude-2.1\n",
      "Model ID: claude-2.0\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Anthropic client\n",
    "client = Anthropic(api_key=_api_keys['ANTHROPIC_API_KEY'])\n",
    "\n",
    "# Get available models\n",
    "available_models = client.models.list()\n",
    "\n",
    "# Print the available models\n",
    "for model in available_models.data:\n",
    "    print(f\"Model ID: {model.id}\")\n",
    "\n",
    "    # The context_window property contains the maximum number of tokens\n",
    "    if hasattr(model, 'context_window'):\n",
    "        print(f\"Max context length: {model.context_window} tokens\")\n",
    "\n",
    "del client , available_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dede8f1",
   "metadata": {},
   "source": [
    "### Select LLM TO  use in chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "508ea649",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model to use in chatbot (use tiny model that is cheap)\n",
    "_model_id = \"claude-3-haiku-20240307\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407c3f47",
   "metadata": {},
   "source": [
    "#### A. Create a ***StateGraph***. A StateGraph object defines the structure of our chatbot as a \"state machine\". \n",
    "  - **State** Consists of the schema of the graph as well as *reducer* functions which specify how to apply updates to the state. \n",
    "    - The schema of the State will be the input schema to all Nodes and Edges in the graph, and can be either a *TypedDict* or a *Pydantic* model. \n",
    "    - All Nodes will emit updates to the State which are then applied using the specified reducer function.\n",
    "\n",
    "  - **Nodes**  Represent units of work/functions the llm and our chatbot can call. Nodes can contain 2 positional arugments. Note, node funcitons are converted to ***RunnableLambdas*** behind the scenes, adding batch and async support to the  node function \n",
    "    1) ***State:*** The schema of the graph*\n",
    "    2) ***Config:*** dictionary containing optional configurable parameters the node can use (ex. thread_id, user info, etc..)*\n",
    "\n",
    "    \n",
    "  - **Edges**  specify how the bot should transition between these functions. *(Edges must be a TypedDict or Pydantic model)*. A node can have MULTIPLE edges. If a node has multiple out-going edges, ***all*** of those destination nodes are executed in parallel as part of the next superstep. There are 4 key types of edges \n",
    "    1) ***Normal Edges:*** go directly from one node to the n ext \n",
    "    2) ***Conditional Edges:*** call a funciton to determine which nodes to go to next \n",
    "    3) ***Entry Point:*** the node that is called first when user input arrivers \n",
    "    4) ***Conditional Entry Point:*** call a funciton to determine which nodes to call first when user input arrives \n",
    "\n",
    "\n",
    "***Note:*** *the Graph State includes the graphs SCHEMA and REDUCER FUNCTIONS  which handel state updates.* **add_messages()** is the reducer function used in this example to append new messages to the list instead of replacing them. Keys without a reducer annotation will overwrite previous values  \n",
    "\n",
    "*Remember: Nodes do the work, edegtes tell what to do next*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35d2585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class State(TypedDict):\n",
    "    # Messages have the type \"list\". The `add_messages` function\n",
    "    # in the annotation defines how this state key should be updated\n",
    "    # in this case we use the reducer function add_messages to  append messages to the list, rather than overwriting them\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "#define config schemea to use to pass configurable parameters in your API \n",
    "#as example i add a string paramter that will be prefixed to each message (not a good idea, but illistrates how to use config)\n",
    "class ConifgSchema(TypedDict):\n",
    "    prefix: str \n",
    "\n",
    "\n",
    "#basic state\n",
    "# The state is a dictionary that contains the current state of the graph\n",
    "# the config contains paramters you want to pass to the node operations\n",
    "graph_builder = StateGraph(State, config_schema=ConifgSchema)\n",
    "\n",
    "\n",
    "### Add a chatbot Node to the graph\n",
    "llm = ChatAnthropic(model=_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5333688",
   "metadata": {},
   "source": [
    "\n",
    "#### B. Add a chatbot Node to StateGraph()\n",
    " - The **chatbot node** function takes the current State as input and returns a dictionary containing an updated messages list under the key \"messages\". **This is the basic pattern for all LangGraph node functions.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "737f7be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: the chatbot node function takes the current State as input and returns a dictionary containing an updated messages list under the key \"messages\". **This is the basic pattern for all LangGraph node functions.**\n",
    "def chatbot(state: State, config: RunnableConfig)-> dict:\n",
    "    prefix = config['configurable'].get(\"prefix\",\"\")\n",
    "    _message = llm.invoke(state[\"messages\"])\n",
    "    \n",
    "    return {\"messages\": [_message]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f19263c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first argument is the unique node name\n",
    "# The second argument is the function or object that will be called whenever the node is used.\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "#Next, add an entry point. This tells our graph where to start its work each time we run it.\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "#set an exit point. This tells the graph \"any time this node is run, you can exit.\"\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "# Finally, we compile the graph. This will check for any errors in the graph and prepare it for use. This creates a new class that we can use to run the graph.\n",
    "# The compiled graph is a subclass of the original graph builder, so we can still use the same methods.\n",
    "# The compiled graph will have a new name, so we can use it to run the graph.\n",
    "# This will also create a new class that we can use to run the graph.\n",
    "graph = graph_builder.compile() \n",
    "\n",
    "#display the graph\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a0e221",
   "metadata": {},
   "source": [
    "### Execute the compiled stateGraph (aka talk to the chatbot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4088bdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Jack Johnson is a singer-songwriter, guitarist, and record producer. Here are some key facts about him:\n",
      "\n",
      "- He was born in 1975 in Hawaii and is known for his laidback, acoustic folk-pop sound.\n",
      "\n",
      "- Some of his most popular songs include \"Sitting, Waiting, Wishing,\" \"Better Together,\" \"Upside Down,\" and \"Good People.\"\n",
      "\n",
      "- He rose to fame in the early 2000s with the release of his debut album Brushfire Fairytales in 2001, which went triple platinum.\n",
      "\n",
      "- His music style is often described as \"beach music\" or \"mellow rock\" and features influences from folk, reggae, and blues.\n",
      "\n",
      "- In addition to his music career, Johnson is also known for his environmental and social activism, supporting causes like sustainable energy and youth education.\n",
      "\n",
      "- He has released a total of 7 studio albums, the most recent being 2017's All the Light Above It Too.\n",
      "\n",
      "- Johnson has won several awards over his career, including a Grammy nomination and multiple Billboard Music Awards.\n",
      "\n",
      "- He is considered one of the most successful and influential singer-songwriters of the 2000s, known for his laidback, feel-good sound.\n",
      "dict_keys(['id', 'model', 'stop_reason', 'stop_sequence', 'usage', 'model_name'])\n",
      "Message ID: msg_01Vxv2qP33tM7QyjN13smHw9\n",
      "Model Used: claude-3-haiku-20240307\n",
      "Chat Stop Reason: end_turn\n",
      "Chat Stop Sequence: None\n",
      "Chat usage: {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 12, 'output_tokens': 269}\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "def stream_graph_updates(user_input: str):\n",
    "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
    "        #import pdb;pdb.set_trace();\n",
    "        \n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "            print(value[\"messages\"][-1].response_metadata.keys())\n",
    "            print(f\"Message ID: {value['messages'][-1].response_metadata['id']}\")\n",
    "            print(f\"Model Used: {value['messages'][-1].response_metadata['model']}\")\n",
    "            print(f\"Chat Stop Reason: {value['messages'][-1].response_metadata['stop_reason']}\")\n",
    "            print(f\"Chat Stop Sequence: {value['messages'][-1].response_metadata['stop_sequence']}\")\n",
    "            print(f\"Chat usage: {value['messages'][-1].response_metadata['usage']}\")\n",
    "\n",
    "# This is a simple loop to get user input and stream the graph updates\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        # fallback if input() is not available\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \" + user_input)\n",
    "        stream_graph_updates(user_input)\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langy3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
