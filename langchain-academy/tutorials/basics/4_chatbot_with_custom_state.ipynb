{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4add1cf",
   "metadata": {},
   "source": [
    "### Part 5: Customizing State \n",
    "\n",
    "Background: you can add additoinal fields to the graph state to define complex  behaviro without relying on the message list (aka free form text)\n",
    "\n",
    "Objective: build a chatbot to search internet to find specific information, and foward that information to a human for review. \n",
    "\n",
    "Example: generate a chatbot to research the birthday of an entity, and add birthday and anme to the keys of the state. \n",
    "\n",
    "\n",
    "Note: Adding information to the state method makes it easily accessable by other graph nodes (i.e downstream nodes that store or process information) as well as the graphs persistence layer\n",
    "\n",
    "\n",
    "#### When to Use **COMMAND** vs **CONDITIONAL EDGES**\n",
    "- use **command** when you need to *both* update the graph state and route to a different node (ex. multi-agent handoffs, where you need to route to a different agent and pass some info to that agent)\n",
    "- use **conditional edges** to route between nodes conditionally without updating the state "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c977acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import API Keys       \n",
    "_root = \"/home/zjc1002/Mounts/code/\"\n",
    "\n",
    "# Specifcy Anthropic model to use \n",
    "_model_id = \"anthropic:claude-3-5-sonnet-20240620\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d0b392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "from typing import Annotated, Dict \n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.tools import tool\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.types import Command, interrupt\n",
    "from langgraph.prebuilt import MessagesState\n",
    "\n",
    "import langchain_core\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.tools import InjectedToolCallId, tool\n",
    "\n",
    "# Custom functions\n",
    "sys.path.append(_root)\n",
    "from  admin.api_keys import _api_keys\n",
    "from admin.sys_ops import _set_env\n",
    "from colab_projects.tutorials.langgraph.tools import get_weather\n",
    "\n",
    "# This anthropic and internet tool requires  API key to be set as a environment variable(s)\n",
    "for api_key in [\"TAVILY_API_KEY\",\"ANTHROPIC_API_KEY\"]:\n",
    "    _set_env( api_key\n",
    "            , value =  _api_keys[api_key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f022ff6",
   "metadata": {},
   "source": [
    "### Defining State Explicitly vs using langgraphs prebuilt MessagesState\n",
    "\n",
    "```Python\n",
    "# Note: Below is the deffinition of langgraphs pre-built MessagesState \n",
    "class MessagesState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570a4722",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Version 1: explicitly defining the messages attriubute as an annotated list using the add_messages reducer\n",
    "class State(TypedDict):\n",
    "    \"\"\"\n",
    "    State for the graph , including 2 custom string parameters(name, birthday) to enable passing values across graph nodes.\n",
    "    \"\"\"\n",
    "\n",
    "    messages: Annotated[list, add_messages]\n",
    "    name: str\n",
    "    birthday: str\n",
    "\n",
    "\n",
    "#Version 2: use langgraphs prebuilt MessagesSate to abstract the messages attribute\n",
    "# We no longer need to define the messages attribute in the State class. Typically, there is more state to track than just messages, so we see people subclass this state and add more fields, like:\n",
    "class State(MessagesState):\n",
    "    \"\"\"\n",
    "    State for the graph , including 2 custom string parameters(name, birthday) to enable passing values across graph nodes.\n",
    "    \"\"\"\n",
    "    name: str\n",
    "    birthday: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ee06fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "# Note that because we are generating a ToolMessage for a state update, we\n",
    "# generally require the ID of the corresponding tool call. We can use\n",
    "# LangChain's InjectedToolCallId to signal that this argument should not\n",
    "# be revealed to the model in the tool's schema.\n",
    "\n",
    "# OBJECTIVE: GENERATE STATE UPDATES FROM INSIDE THE TOOL\n",
    "def human_assistance(\n",
    "    name: str\n",
    "    , birthday: str\n",
    "    , tool_call_id: Annotated[str, InjectedToolCallId]\n",
    ") -> str:\n",
    "    \n",
    "    \"\"\"Request assistance from a human.\"\"\"\n",
    "\n",
    "    print('AI MODEL THINKS NAME IS:', name)\n",
    "    print('AI MODEL THINKS BIRTHDAY IS:', birthday)\n",
    "\n",
    "    # We can use the interrupt function to ask a human reviewer to\n",
    "    human_response = interrupt(\n",
    "        {\n",
    "            \"question\": \"Is this correct?\",\n",
    "            \"name\": name,\n",
    "            \"birthday\": birthday,\n",
    "        },\n",
    "    )\n",
    "    # If the information is correct, update the state as-is.\n",
    "    if human_response.get(\"correct\", \"\").lower().startswith(\"y\"):\n",
    "        print(\"Human reviewer confirmed the information.\")\n",
    "        verified_name = name\n",
    "        verified_birthday = birthday\n",
    "        response = \"Correct\"\n",
    "        \n",
    "    # Otherwise, receive information from the human reviewer.\n",
    "    else:\n",
    "        print(\"Human reviewer provided corrections.\")\n",
    "        verified_name = human_response.get(\"name\", name)\n",
    "        verified_birthday = human_response.get(\"birthday\", birthday)\n",
    "        response = f\"Made a correction: {human_response}\"\n",
    "\n",
    "    # This time we explicitly update the state with a ToolMessage inside\n",
    "    # the tool.\n",
    "    state_update = {\n",
    "        \"name\": verified_name,\n",
    "        \"birthday\": verified_birthday,\n",
    "        \"messages\": [ToolMessage(response, tool_call_id=tool_call_id)],\n",
    "    }\n",
    "\n",
    "\n",
    "    # We return a Command object in the tool to update our state.\n",
    "    return Command(update=state_update)\n",
    "\n",
    "\n",
    "def chatbot(state: State) -> Command:\n",
    "    \"\"\"Process user inputs and generate AI responses in the conversation flow.\n",
    "    \n",
    "    This function handles the core chatbot functionality by invoking the LLM with \n",
    "    the current conversation context. It ensures proper tool handling by limiting\n",
    "    to one tool call at a time to support the human-in-the-loop workflow.\n",
    "    \n",
    "    Args:\n",
    "        state (State): The current conversation state containing message history\n",
    "        llm_with_tools (RunnableBinding): The language model with bound tools\n",
    "        \n",
    "    Returns:\n",
    "        Command: Dictionary containing the AI response message\n",
    "    \"\"\"\n",
    "    # Process the conversation state and generate a response\n",
    "    message = llm_with_tools.invoke(state[\"messages\"])\n",
    "    assert(len(message.tool_calls) <= 1)\n",
    "    return {\"messages\": [message]}\n",
    "\n",
    "\n",
    "def stream_graph_updates(user_input:str , graph ,  config:Dict): \n",
    "    \n",
    "    \"\"\"Stream updates from a LangGraph execution and print the responses.\n",
    "    \n",
    "    This function processes a user input through a LangGraph conversation flow,\n",
    "    streaming the results as they become available and printing each message.\n",
    "    \n",
    "    Args:\n",
    "        user_input (str): The user's question or instruction to process\n",
    "        graph (CompiledStateGraph): The compiled LangGraph object that defines the conversation flow\n",
    "        config (Dict): Configuration settings for the graph execution, including thread ID\n",
    "    \"\"\"\n",
    "\n",
    "    events = graph.stream(\n",
    "        {'messages': [{'role': \"user\", \"content\": user_input}]}\n",
    "         , config\n",
    "         , stream_mode = 'values'\n",
    "         )\n",
    "    \n",
    "    # Print the messages as they are received\n",
    "    for event in events:\n",
    "        if \"messages\" in event:\n",
    "            event[\"messages\"][-1].pretty_print()\n",
    "\n",
    "\n",
    "def stream_graph_updates_human_input(human_response:str\n",
    "                                     , graph \n",
    "                                     ,  config:Dict): \n",
    "    \"\"\"j\n",
    "    Stream updates from a LangGraph execution and print the responses.\n",
    "    \"\"\"\n",
    "    \n",
    "    events = graph.stream(\n",
    "        (human_response)\n",
    "         , config\n",
    "         , stream_mode = 'values'\n",
    "         )\n",
    "    \n",
    "    for event in events:\n",
    "        if \"messages\" in event:\n",
    "            event[\"messages\"][-1].pretty_print()\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bf6811e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#specify tools \n",
    "internet_search = TavilySearch(max_results=2)\n",
    "tools = [internet_search, human_assistance, get_weather]\n",
    "\n",
    "#compile tools and llm \n",
    "llm = init_chat_model(_model_id) #generalized method to load any supported decoder for use as chatbot \n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "tool_node = ToolNode(tools=tools)\n",
    "\n",
    "######\n",
    "#CREATE THE GRAPH\n",
    "######\n",
    "\n",
    "#compile the graph\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "#add chatbot and tools to the graph\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "#add tool node to the graph\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "# TOOLS are processed and evaluated for use via conditional edges\n",
    "# The tools_condition function is a custom function that determines whether the chatbot should use a tool based on the current state of the conversation.\n",
    "# When add_conditional_edges is called with the \"chatbot\" node and this function, it's establishing the logic that determines where the conversation flow should go after the chatbot node processes a message.\n",
    "# This creates a decision point in the graph where the conversation can either:Route to the tools node if the chatbot determines it needs external information or Loop back to the chatbot or go to another node if no tools are needed\n",
    "# This conditional routing allows the chatbot to dynamically decide when to use the provided tools (internet search, human assistance, or weather information) based on the conversation context.\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\") #generates / creates a path from tools to chatbot\n",
    "graph_builder.add_edge(START, \"chatbot\") #defines the starting point of the graph\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb1f30fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Can you look up when LangGraph was released? When you have the answer, use the human_assistance tool for review\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"Certainly! I'll search for information about LangGraph's release date and then use the human_assistance tool for review. Let's start with the search.\", 'type': 'text'}, {'id': 'toolu_01WYwZyEAwa2C3eAnLjPQyP5', 'input': {'query': 'When was LangGraph released?'}, 'name': 'tavily_search', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search (toolu_01WYwZyEAwa2C3eAnLjPQyP5)\n",
      " Call ID: toolu_01WYwZyEAwa2C3eAnLjPQyP5\n",
      "  Args:\n",
      "    query: When was LangGraph released?\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"When was LangGraph released?\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"title\": \"LangGraph Quickstart\", \"url\": \"https://colab.research.google.com/github/langchain-ai/langgraph/blob/main/docs/docs/tutorials/introduction.ipynb\", \"content\": \"I can now provide you with the correct information about LangGraph's release date. LangGraph was initially released on January 17, 2024. This information comes from the human assistance correction, which is more accurate than the search results I initially found. To summarize: 1. LangGraph's original release date: January 17, 2024 2.\", \"score\": 0.92715925, \"raw_content\": null}, {\"title\": \"Releases · langchain-ai/langgraph - GitHub\", \"url\": \"https://github.com/langchain-ai/langgraph/releases\", \"content\": \"Releases · langchain-ai/langgraph GitHub Copilot Write better code with AI GitHub Advanced Security Find and fix vulnerabilities Code Search Find more, search less Why GitHub GitHub Advanced Security Enterprise-grade security features Search code, repositories, users, issues, pull requests... Search Releases: langchain-ai/langgraph Releases · langchain-ai/langgraph github-actions View all tags github-actions View all tags langgraph: fix messages streaming for list of Commands (#4379) github-actions View all tags Changes since cli==0.2.6 github-actions View all tags Changes since sdk==0.1.62 fix: threads search sorting defaults (#4365) github-actions View all tags Changes since cli==0.2.5 github-actions View all tags Changes since sdk==0.1.61 github-actions View all tags github-actions View all tags github-actions View all tags Changes since cli==0.2.4 github-actions View all tags © 2025 GitHub, Inc. Footer navigation\", \"score\": 0.30000725, \"raw_content\": null}], \"response_time\": 1.79}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"Thank you for providing that information. Based on the search results, I couldn't find a specific release date for LangGraph. The search results don't provide a clear answer to when LangGraph was released. Let's use the human_assistance tool to get more accurate information and review.\", 'type': 'text'}, {'id': 'toolu_01QyERRBMXnNeM1gEm6fSA4f', 'input': {'name': 'Assistant', 'birthday': '2023-01-01'}, 'name': 'human_assistance', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  human_assistance (toolu_01QyERRBMXnNeM1gEm6fSA4f)\n",
      " Call ID: toolu_01QyERRBMXnNeM1gEm6fSA4f\n",
      "  Args:\n",
      "    name: Assistant\n",
      "    birthday: 2023-01-01\n",
      "AI MODEL THINKS NAME IS: Assistant\n",
      "AI MODEL THINKS BIRTHDAY IS: 2023-01-01\n"
     ]
    }
   ],
   "source": [
    "#inital pass at trying to identify the name and birthday of langgraph\n",
    "user_input = (\n",
    "    \"Can you look up when LangGraph was released? \"\n",
    "    \"When you have the answer, use the human_assistance tool for review\"\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "\n",
    "stream_graph_updates(user_input , graph ,  config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9890c610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Please provide your response in the following format:\n",
      "correct=yes/no; name=NAME; birthday=DATE\n",
      "Example: correct=yes; name=LangGraph; birthday=Jan 17, 2024\n",
      "Or just 'correct=yes' if all information is correct\n",
      "Structured input received: {'correct': 'no', 'name': 'LangGraph', 'birthday': '10/02/2023'}\n"
     ]
    }
   ],
   "source": [
    "def get_structured_human_input():\n",
    "    \"\"\"\n",
    "    Get structured input from a human in dictionary format.\n",
    "    Returns a Command object with the correct format for resume data.\n",
    "    \"\"\"\n",
    "    print(\"\\nPlease provide your response in the following format:\")\n",
    "    print(\"correct=yes/no; name=NAME; birthday=DATE\")\n",
    "    print(\"Example: correct=yes; name=LangGraph; birthday=Jan 17, 2024\")\n",
    "    print(\"Or just 'correct=yes' if all information is correct\")\n",
    "    \n",
    "    user_input = input(\"\\nYour response: \")\n",
    "    \n",
    "    # Parse the input\n",
    "    response = {}\n",
    "    if \"correct=yes\" in user_input.lower():\n",
    "        response[\"correct\"] = \"yes\"\n",
    "    else:\n",
    "        response[\"correct\"] = \"no\"\n",
    "        \n",
    "    # Extract name and birthday if provided\n",
    "    if \"name=\" in user_input:\n",
    "        name_part = user_input.split(\"name=\")[1].split(\";\")[0].strip()\n",
    "        response[\"name\"] = name_part\n",
    "    \n",
    "    if \"birthday=\" in user_input:\n",
    "        birthday_part = user_input.split(\"birthday=\")[1].split(\";\")[0].strip()\n",
    "        response[\"birthday\"] = birthday_part\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Get structured input from the human\n",
    "human_input = get_structured_human_input()\n",
    "print(\"Structured input received:\", human_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95ca1243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Command(resume={'correct': 'no', 'name': 'LangGraph', 'birthday': '10/02/2023'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the model cannot identify the birthday and name of LangGraph, so we use the structured response from human\n",
    "human_command = Command(resume=human_input, )\n",
    "human_command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fc5d824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"Thank you for providing that information. Based on the search results, I couldn't find a specific release date for LangGraph. The search results don't provide a clear answer to when LangGraph was released. Let's use the human_assistance tool to get more accurate information and review.\", 'type': 'text'}, {'id': 'toolu_01QyERRBMXnNeM1gEm6fSA4f', 'input': {'name': 'Assistant', 'birthday': '2023-01-01'}, 'name': 'human_assistance', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  human_assistance (toolu_01QyERRBMXnNeM1gEm6fSA4f)\n",
      " Call ID: toolu_01QyERRBMXnNeM1gEm6fSA4f\n",
      "  Args:\n",
      "    name: Assistant\n",
      "    birthday: 2023-01-01\n",
      "AI MODEL THINKS NAME IS: Assistant\n",
      "AI MODEL THINKS BIRTHDAY IS: 2023-01-01\n",
      "Human reviewer provided corrections.\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: human_assistance\n",
      "\n",
      "Made a correction: {'correct': 'no', 'name': 'LangGraph', 'birthday': '10/02/2023'}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Thank you for the human assistance. I apologize for the confusion in my previous response. The human assistance has provided a correction regarding LangGraph's release date. \n",
      "\n",
      "According to the human assistance:\n",
      "\n",
      "LangGraph was released on October 2, 2023 (10/02/2023).\n",
      "\n",
      "This information is more specific and accurate than what I initially found through the search. It's important to note that this date represents the initial release of LangGraph.\n",
      "\n",
      "Is there anything else you would like to know about LangGraph or its release?\n"
     ]
    }
   ],
   "source": [
    "stream_graph_updates_human_input(human_command\n",
    "                                     , graph \n",
    "                                     ,  config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5f2cfb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Thank you for the human assistance. It appears that the information I found was not entirely accurate. The human has provided a correction:\n",
      "\n",
      "LangGraph was actually released on January 1, 2022 (2022-01-01).\n",
      "\n",
      "This date is earlier than what we found in our initial search, which is not unusual for software projects. Sometimes, the first public release or announcement might come after the initial development or internal release.\n",
      "\n",
      "To summarize:\n",
      "- LangGraph was released on January 1, 2022.\n",
      "- The information from our initial search about recent versions and ongoing development is still relevant, showing that the project is actively maintained and updated.\n",
      "\n",
      "Is there anything else you'd like to know about LangGraph or its release?\n"
     ]
    }
   ],
   "source": [
    "#we manually set the name and birthday to LangGraph and Jan 17, 2024\n",
    "#and then pass the command to the graph for processing\n",
    "events = graph.stream(human_command\n",
    "                      , config, stream_mode=\"values\")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "423fcda7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'LangGraph', 'birthday': '10/02/1988'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view the updated state of the graph\n",
    "snapshot = graph.get_state(config)\n",
    "{k: v for k, v in snapshot.values.items() if k in (\"name\", \"birthday\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e616633",
   "metadata": {},
   "source": [
    "#### Manually Updating a graphs state  \n",
    "*A) at any point, we can manually override a key in the state of the graph*\n",
    "\n",
    "*B) after setting state, if we call get_state(with correct config) we can see the updated values reflected in the graph state*\n",
    "\n",
    "##### WARNING: Use of the interrupt function is generally recommended instead, as it allows data to be transmitted in a human-in-the-loop interaction independently of state updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a2ba64e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'LangGraph(test)', 'birthday': 'Jan 17, 2024'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A\n",
    "graph.update_state(config,{'name': 'LangGraph(test)', 'birthday': 'Jan 17, 2024'})\n",
    "\n",
    "#B\n",
    "snapshot = graph.get_state(config)\n",
    "{k: v for k, v in snapshot.values.items() if k in (\"name\", \"birthday\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29810a3a",
   "metadata": {},
   "source": [
    "### Part 6: Time Travel \n",
    "- enabling  model to start from any prior response, and *branch off* to explore alternate outcomes\n",
    "- enable useres to *rewind* the chatbots work to fix mistakes or try a new approach\n",
    "\n",
    "\n",
    "##### **Objective:** rewind your graph by fetching a checkpoint using the graphs **get_state_history()** method. then resume execution from this previous state of the conversation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ddea81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Messages:  6 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  5 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  4 Next:  ('tools',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  3 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  2 Next:  ('tools',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  1 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  0 Next:  ('__start__',)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#replay the full state history to see everything that occurred.\n",
    "#Notice that checkpoints are saved for every step of the graph. This spans invocations so you can rewind across a full thread's history.\n",
    "    \n",
    "to_replay = None\n",
    "for state in graph.get_state_history(config):\n",
    "    print(\"Num Messages: \", len(state.values[\"messages\"]), \"Next: \", state.next)\n",
    "    print(\"-\" * 80)\n",
    "    if len(state.values[\"messages\"]) == 6:\n",
    "        # We are somewhat arbitrarily selecting a specific state based on the number of chat messages in the state.\n",
    "        to_replay = state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5751e9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "{'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f02b659-d881-6d77-8005-f5d27be87c8a'}}\n",
      "Thank you for the human assistance. I apologize for the confusion in my previous response. The human assistance has provided a correction regarding LangGraph's release date. \n",
      "\n",
      "According to the human assistance:\n",
      "\n",
      "LangGraph was released on October 2, 2023 (10/02/2023).\n",
      "\n",
      "This information is more specific and accurate than what I initially found through the search. It's important to note that this date represents the initial release of LangGraph.\n",
      "\n",
      "Is there anything else you would like to know about LangGraph or its release?\n"
     ]
    }
   ],
   "source": [
    "#the checkpoint's config (to_replay.config) contains a checkpoint_id timestamp. \n",
    "# Providing this checkpoint_id value tells LangGraph's checkpointer to load the state from that moment in time\n",
    "\n",
    "print(to_replay.next)\n",
    "print(to_replay.config)\n",
    "print(to_replay.values[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fc3b5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Thank you for the human assistance. I apologize for the confusion in my previous response. The human assistance has provided a correction regarding LangGraph's release date. \n",
      "\n",
      "According to the human assistance:\n",
      "\n",
      "LangGraph was released on October 2, 2023 (10/02/2023).\n",
      "\n",
      "This information is more specific and accurate than what I initially found through the search. It's important to note that this date represents the initial release of LangGraph.\n",
      "\n",
      "Is there anything else you would like to know about LangGraph or its release?\n"
     ]
    }
   ],
   "source": [
    "# The `checkpoint_id` in the `to_replay.config` corresponds to a state we've persisted to our checkpointer.\n",
    "for event in graph.stream(None, to_replay.config, stream_mode=\"values\"):\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d6144c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "YES, please tell me how to tie shoes\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"Certainly! I'd be happy to explain how to tie shoes. Since this is a general knowledge question and doesn't require real-time information, I'll provide you with a step-by-step guide. However, to ensure the information is accurate and up-to-date, let's use the Tavily search engine to double-check the steps.\", 'type': 'text'}, {'id': 'toolu_01WMStjsw6tmWgH1ZYdxxd6x', 'input': {'query': 'How to tie shoes step by step'}, 'name': 'tavily_search', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search (toolu_01WMStjsw6tmWgH1ZYdxxd6x)\n",
      " Call ID: toolu_01WMStjsw6tmWgH1ZYdxxd6x\n",
      "  Args:\n",
      "    query: How to tie shoes step by step\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"How to tie shoes step by step\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"title\": \"How to Tie Your Shoes: 4 Easy Techniques (with Videos) - wikiHow\", \"url\": \"https://www.wikihow.com/Tie-Your-Shoes\", \"content\": \"This way, when you instruct them to make a loop with the lace, it can look like trying to form a “tree” by always making sure the green part of the lace is at the top of the loop, like the leaves at the top of a tree.[2] X Research source As you tighten the laces, you should now have two loops on either side of the shoe and a nice, clean tie in the middle of the shoe.[21] X Research source   Article SummaryXTo tie your shoes using the bunny ear method, start by cross the laces over each other, and pass one of the laces through the loop.\", \"score\": 0.77731717, \"raw_content\": null}, {\"title\": \"How to Tie a Shoe Step by Step - YouTube\", \"url\": \"https://www.youtube.com/watch?v=TqPCGGHoxsE\", \"content\": \"How to Tie a Shoe Step by Step - The OT Way!My son still couldn't tie his shoe as he entered 2nd grade, despite our best and most patient efforts. Here's the\", \"score\": 0.4709562, \"raw_content\": null}], \"response_time\": 1.66}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Based on the search results and general knowledge, I can provide you with a step-by-step guide on how to tie shoes using the standard method. Here's how to do it:\n",
      "\n",
      "1. Start with untied laces: Make sure your shoe is on your foot and the laces are loose.\n",
      "\n",
      "2. Cross the laces: Take one lace in each hand and cross the right lace over the left lace.\n",
      "\n",
      "3. Create the base knot: \n",
      "   - Take the lace that's now on top (originally the right lace).\n",
      "   - Bring it under and through the loop created by crossing the laces.\n",
      "   - Pull both laces tight to create a basic knot at the base.\n",
      "\n",
      "4. Make the first \"bunny ear\":\n",
      "   - Take one lace and form it into a loop (like a bunny ear).\n",
      "   - Hold this loop with your thumb and index finger.\n",
      "\n",
      "5. Make the second \"bunny ear\":\n",
      "   - Do the same with the other lace, creating a second loop.\n",
      "\n",
      "6. Cross the loops:\n",
      "   - Take the second loop (in your right hand) and cross it over the first loop.\n",
      "\n",
      "7. Create the final knot:\n",
      "   - Push the second loop (right loop) behind and through the hole created by crossing the loops.\n",
      "\n",
      "8. Pull tight:\n",
      "   - Hold onto both loops and pull them tight to secure the knot.\n",
      "\n",
      "9. Adjust if needed:\n",
      "   - Make sure both loops are roughly the same size for a neat appearance.\n",
      "\n",
      "This method is often called the \"bunny ears\" method and is particularly easy for children to learn. It results in a standard bow knot that's secure and easy to untie when needed.\n",
      "\n",
      "Remember, practice makes perfect. It might take a few tries to get the hang of it, but with repetition, tying shoes becomes an automatic skill.\n",
      "\n",
      "Is there anything specific about shoe-tying you'd like me to clarify or expand on?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "YES,  who invented the shoe?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"Certainly! I'll search for information about who invented the shoe. Let me look that up for you.\", 'type': 'text'}, {'id': 'toolu_017PcmyY9hr6Zhjub245H4hj', 'input': {'query': 'Who invented the shoe?'}, 'name': 'tavily_search', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search (toolu_017PcmyY9hr6Zhjub245H4hj)\n",
      " Call ID: toolu_017PcmyY9hr6Zhjub245H4hj\n",
      "  Args:\n",
      "    query: Who invented the shoe?\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"Who invented the shoe?\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"title\": \"Jan Ernst Matzeliger - Wikipedia\", \"url\": \"https://en.wikipedia.org/wiki/Jan_Ernst_Matzeliger\", \"content\": \"Jan Ernst Matzeliger (September 15, 1852 - August 24, 1889) was a Surinamese-American inventor whose automated lasting machine brought significant change to the manufacturing of shoes. The Consolidated Lasting Machine Company company was founded to make his shoe making devices. [1][better source needed]\", \"score\": 0.5553635, \"raw_content\": null}, {\"title\": \"Jan Matzeliger - Invention, Facts & Education - Biography\", \"url\": \"https://www.biography.com/inventors/jan-matzeliger\", \"content\": \"Jan Matzeliger was an inventor of Surinamese and Dutch descent best known for patenting the shoe lasting machine, which made footwear more affordable.\", \"score\": 0.5122296, \"raw_content\": null}], \"response_time\": 1.53}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Thank you for your question about who invented the shoe. After searching for information, I can provide you with some insights, although it's important to note that the invention of shoes as a concept dates back to prehistoric times and doesn't have a single inventor. However, I can tell you about a significant inventor who revolutionized shoe manufacturing:\n",
      "\n",
      "Jan Ernst Matzeliger (September 15, 1852 - August 24, 1889) made a major contribution to shoe manufacturing. While he didn't invent shoes themselves, he invented something that greatly impacted shoe production:\n",
      "\n",
      "1. Jan Ernst Matzeliger was a Surinamese-American inventor.\n",
      "2. He invented and patented the shoe lasting machine.\n",
      "3. This machine automated a critical step in shoe manufacturing, making shoes more affordable and accessible to the general public.\n",
      "4. The Consolidated Lasting Machine Company was founded to produce his shoe-making devices.\n",
      "\n",
      "It's worth noting that shoes as a concept have existed for thousands of years, evolving from simple foot protection to more complex designs over time. The earliest known shoes date back to prehistoric times, and various cultures have contributed to the development of footwear throughout history.\n",
      "\n",
      "Matzeliger's invention in the late 19th century was a significant leap forward in shoe manufacturing technology, but it's not accurate to say he invented shoes themselves.\n",
      "\n",
      "Is there anything specific about the history of shoes or shoe manufacturing that you'd like to know more about?\n"
     ]
    }
   ],
   "source": [
    "for event in graph.stream(\n",
    "    \n",
    "    {'messages':[{'role':'user','content':'YES, please tell me how to tie shoes'}]}\n",
    "     ,  to_replay.config, stream_mode=\"values\"):\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()\n",
    "\n",
    "for event in graph.stream(\n",
    "    \n",
    "    {'messages':[{'role':'user','content':'YES,  who invented the shoe?'}]}\n",
    "     ,  to_replay.config, stream_mode=\"values\"):\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92a146f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Messages:  10 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  9 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  8 Next:  ('tools',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  7 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  6 Next:  ('__start__',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  10 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  9 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  8 Next:  ('tools',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  7 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  6 Next:  ('__start__',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  10 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  9 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  8 Next:  ('tools',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  7 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  6 Next:  ('__start__',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  6 Next:  ('__start__',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  6 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  5 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  4 Next:  ('tools',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  3 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  2 Next:  ('tools',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  1 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  0 Next:  ('__start__',)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for state in graph.get_state_history(config):\n",
    "    print(\"Num Messages: \", len(state.values[\"messages\"]), \"Next: \", state.next)\n",
    "    print(\"-\" * 80)\n",
    "#    if len(state.values[\"messages\"]) == 6:\n",
    "        # We are somewhat arbitrarily selecting a specific state based on the number of chat messages in the state.\n",
    "#        to_replay = state"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langy3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
