{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c9e547f",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-3/streaming-interruption.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239464-lesson-1-streaming)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319adfec-2d0a-49f2-87f9-275c4a32add2",
   "metadata": {},
   "source": [
    "# Streaming\n",
    "\n",
    "## Review\n",
    "\n",
    "In module 2, covered a few ways to customize graph state and memory.\n",
    " \n",
    "We built up to a Chatbot with external memory that can sustain long-running conversations. \n",
    "\n",
    "## Goals\n",
    "\n",
    "This module will dive into `human-in-the-loop`, which builds on memory and allows users to interact directly with graphs in various ways. \n",
    "\n",
    "To set the stage for `human-in-the-loop`, we'll first dive into streaming, which provides several ways to visualize graph output (e.g., node state or chat model tokens) over the course of execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db024d1f-feb3-45a0-a55c-e7712a1feefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langgraph langchain_openai langgraph_sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d7e41b-c6ba-4e47-b645-6c110bede549",
   "metadata": {},
   "source": [
    "## Streaming\n",
    "\n",
    "LangGraph is built with [first class support for streaming](https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming).\n",
    "\n",
    "Let's set up our Chatbot from Module 2, and show various way to stream outputs from the graph during execution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b430d92-f595-4322-a56e-06de7485daa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass, sys\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "#Import API Keys(storing them all in a seperate file so i run into less issues with git)\n",
    "_root = \"/home/zjc1002/Mounts/code/\"\n",
    "_langsmith_trace = 'true'\n",
    "_langsmith_project = 'zjc_custom_v1'\n",
    "_anthropic_model = 'claude-3-haiku-20240307'\n",
    "_temparate = 0\n",
    "_max_tokens = 4000\n",
    "_streaming = True\n",
    "_system_message = None\n",
    "_db_path = \"/home/zjc1002/Mounts/data/langgraph_memory/state_db/example1.db\"\n",
    "# This is a basic config to enable tracing of conversations and  utilization of memory\n",
    "_config = {'configurable': {'thread_id':\"1\"}}\n",
    "\n",
    "# Custom functions\n",
    "sys.path.append(_root)\n",
    "from  admin.api_keys import _api_keys\n",
    "from admin.sys_ops import _set_env\n",
    "from langgraph_projects.tools import get_weather, get_date, multiply, add, divide\n",
    "\n",
    "# This anthropic and internet tool requires  API key to be set as a environment variable(s)\n",
    "for api_key in [\"TAVILY_API_KEY\",\"ANTHROPIC_API_KEY\",'OPENAI_API_KEY','LANGSMITH_API_KEY']:\n",
    "    _set_env(api_key\n",
    "            ,value =  _api_keys[api_key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0682fc",
   "metadata": {},
   "source": [
    "Note that we use `RunnableConfig` with `call_model` to enable token-wise streaming. This is [only needed with python < 3.11](https://langchain-ai.github.io/langgraph/how-tos/streaming-tokens/). We include in case you are running this notebook in CoLab, which will use python 3.x. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d7321e0-0d99-4efe-a67b-74c12271859b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "import langchain_core\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "from typing import Dict, List, Union, Literal\n",
    "# LLM\n",
    "model =  ChatAnthropic(\n",
    "    model=_anthropic_model,\n",
    "    temperature=_temparate,\n",
    "    max_tokens=_max_tokens,\n",
    "    streaming=_streaming,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "\n",
    "# State \n",
    "class State(MessagesState):\n",
    "    summary: str\n",
    "\n",
    "# Define the logic to call the model\n",
    "def call_model(state: State, config: RunnableConfig\n",
    "               ) -> Dict[str, langchain_core.messages.ai.AIMessage]:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        state (State): _description_\n",
    "        config (RunnableConfig): _description_\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Union[str, List[RemoveMessage]]]: _description_\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get summary if it exists\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # If there is summary, then we add it\n",
    "    if summary:\n",
    "        \n",
    "        # Add summary to system message\n",
    "        system_message = f\"Summary of conversation earlier: {summary}\"\n",
    "\n",
    "        # Append summary to any newer messages\n",
    "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "    \n",
    "    else:\n",
    "        messages = state[\"messages\"]\n",
    "    \n",
    "    response = model.invoke(messages, config)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "def summarize_conversation(state: State) -> Dict:\n",
    "    \"\"\"Summarize the conversation so far.\n",
    "    This is done by taking the last 6 messages and creating a summary of them.\n",
    "    The summary is then added to the state, and the messages are removed from the state.\n",
    "    Args:\n",
    "        state (State): _description_\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Union[str, List[RemoveMessage]]]: _description_\n",
    "    \"\"\"\n",
    "    # First, we get any existing summary\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # Create our summarization prompt \n",
    "    if summary:\n",
    "        \n",
    "        # A summary already exists\n",
    "        summary_message = (\n",
    "            f\"This is summary of the conversation to date: {summary}\\n\\n\"\n",
    "            \"Extend the summary by taking into account the new messages above:\"\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        summary_message = \"Create a summary of the conversation above:\"\n",
    "\n",
    "    # Add prompt to our history\n",
    "    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
    "    response = model.invoke(messages)\n",
    "    \n",
    "    # Delete all but the 2 most recent messages\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "    return {\"summary\": response.content, \"messages\": delete_messages}\n",
    "\n",
    "# Determine whether to end or summarize the conversation\n",
    "def should_continue(state: State) -> Literal[\"summarize_conversation\",\"__end__\"]:\n",
    "    \n",
    "    \"\"\"Return the next node to execute.\"\"\"\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # If there are more than six messages, then we summarize the conversation\n",
    "    if len(messages) > 6:\n",
    "        return \"summarize_conversation\"\n",
    "    \n",
    "    # Otherwise we can just end\n",
    "    return \"__end__\"\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"conversation\", call_model)\n",
    "workflow.add_node(summarize_conversation)\n",
    "\n",
    "# Set the entrypoint as conversation\n",
    "workflow.add_edge(START, \"conversation\")\n",
    "workflow.add_conditional_edges(\"conversation\"\n",
    "                               , should_continue\n",
    "                               , {\n",
    "                                   \"summarize_conversation\": \"summarize_conversation\",\n",
    "                                   \"__end__\": END\n",
    "                               })\n",
    "                               \n",
    "workflow.add_edge(\"summarize_conversation\", END)\n",
    "\n",
    "# Compile\n",
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1a83e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "It's nice to meet you, Lance! I'm Claude, an AI assistant created by Anthropic. How can I help you today?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your name is Lance, as you introduced yourself at the beginning of our conversation.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That's great that you're a fan of the 49ers! I don't have a strong allegiance to any particular sports teams, but I can certainly appreciate the passion and excitement that comes with being a fan. Do you have a favorite player or moment from the 49ers that you really enjoy?\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"hi! I'm Lance\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()\n",
    "\n",
    "input_message = HumanMessage(content=\"what's my name?\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()\n",
    "\n",
    "input_message = HumanMessage(content=\"i like the 49ers!\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f847a787-b301-488c-9b58-cba9f389f55d",
   "metadata": {},
   "source": [
    "### Streaming full state\n",
    "\n",
    "Now, let's talk about ways to [stream our graph state](https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming).\n",
    "\n",
    "`.stream` and `.astream` are sync and async methods for streaming back results. \n",
    " \n",
    "LangGraph supports a few [different streaming modes](https://langchain-ai.github.io/langgraph/how-tos/stream-values/) for [graph state](https://langchain-ai.github.io/langgraph/how-tos/stream-values/):\n",
    " \n",
    "* `values`: This streams the full state of the graph after each node is called.\n",
    "* `updates`: This streams updates to the state of the graph after each node is called.\n",
    "\n",
    "![values_vs_updates.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbaf892d24625a201744e5_streaming1.png)\n",
    "\n",
    "Let's look at `stream_mode=\"updates\"`.\n",
    "\n",
    "Because we stream with `updates`, we only see updates to the state after node in the graph is run.\n",
    "\n",
    "Each `chunk` is a dict with `node_name` as the key and the updated state as the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a6f8ae9-f244-40c5-a2da-618b72631b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conversation': {'messages': AIMessage(content=\"Okay, got it - your name is Lance. It's nice to meet you again, Lance! I'm always happy to chat about sports or any other topics you're interested in. What do you enjoy most about being a 49ers fan?\", additional_kwargs={}, response_metadata={'model_name': 'claude-3-haiku-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None}, id='run--b8659fca-e0c2-43a0-bd09-e223c8a23855-0', usage_metadata={'input_tokens': 154, 'output_tokens': 60, 'total_tokens': 214, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})}}\n",
      "{'summarize_conversation': {'summary': 'Here is a summary of the conversation so far:\\n\\nThe conversation began with you introducing yourself as Lance. I then introduced myself as Claude, an AI assistant. \\n\\nYou expressed that you are a fan of the 49ers football team. I acknowledged this and asked if you had a favorite player or moment as a 49ers fan.\\n\\nYou then repeated that your name is Lance, even though I had already established that in the initial part of the conversation.\\n\\nOverall, the key points are:\\n- You introduced yourself as Lance\\n- You shared that you are a 49ers fan\\n- I engaged with you about your fandom and asked follow-up questions\\n- You reiterated your name at the end, even though it had already been established\\n\\nPlease let me know if you would like me to clarify or expand on anything in this summary.', 'messages': [RemoveMessage(content='', additional_kwargs={}, response_metadata={}, id='9f8bfe1b-b0f8-491a-b206-8f7690a54b4f'), RemoveMessage(content='', additional_kwargs={}, response_metadata={}, id='run--e4eb54ea-5aa1-4bd9-a204-31c8e4024f58-0'), RemoveMessage(content='', additional_kwargs={}, response_metadata={}, id='826eba2f-f199-4a47-8c22-dafce816ea7b'), RemoveMessage(content='', additional_kwargs={}, response_metadata={}, id='run--030caf95-018a-4ed4-b5f2-fc210d65090c-0'), RemoveMessage(content='', additional_kwargs={}, response_metadata={}, id='2ab193b7-dab5-494c-9f6d-6508661adc1b'), RemoveMessage(content='', additional_kwargs={}, response_metadata={}, id='run--68e8e9da-3db1-4c7b-b7e3-65de766c2adb-0')]}}\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "for chunk in graph.stream({\"messages\": [HumanMessage(content=\"hi! I'm Lance\")]}, config, stream_mode=\"updates\"):\n",
    "    print(chunk)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4882e9-07dd-4d70-866b-dfc530418cad",
   "metadata": {},
   "source": [
    "Let's now just print the state update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c859c777-cb12-4682-9108-6b367e597b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Okay, I understand you are introducing yourself as Lance again. As I mentioned before, I already knew your name was Lance from our earlier conversation. Is there anything else you'd like to discuss? I'm happy to continue our conversation about the 49ers or any other topics you're interested in.\n"
     ]
    }
   ],
   "source": [
    "# Start conversation\n",
    "for chunk in graph.stream({\"messages\": [HumanMessage(content=\"hi! I'm Lance\")]}, config, stream_mode=\"updates\"):\n",
    "    chunk['conversation'][\"messages\"].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583bf219-6358-4d06-ae99-c40f43569fda",
   "metadata": {},
   "source": [
    "Now, we can see `stream_mode=\"values\"`.\n",
    "\n",
    "This is the `full state` of the graph after the `conversation` node is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ee763f8-6d1f-491e-8050-fb1439e116df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Lance\n",
      "---------------------------------------------------------------------------\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Lance\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "It's nice to meet you, Lance! I'm Claude, an AI assistant created by Anthropic. How can I help you today?\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Start conversation, again\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"hi! I'm Lance\")\n",
    "for event in graph.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
    "\n",
    "    #NOTE: the keys in the event are the keys specified in t he graph State\n",
    "    for m in event['messages']:\n",
    "        m.pretty_print()\n",
    "    print(\"---\"*25)\n",
    "\n",
    "#get a static state view, to decompose and undersstand the elements of the state\n",
    "input_message = HumanMessage(content=\"can you find me the best resturant in Cary NC.\")\n",
    "e = graph.stream({\"messages\": [input_message]}, config, stream_mode=\"values\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294e78c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'can you find me the best resturant in Cary NC.',\n",
       " 'additional_kwargs': {},\n",
       " 'response_metadata': {},\n",
       " 'type': 'human',\n",
       " 'name': None,\n",
       " 'id': 'e38fb98f-4667-4df1-865e-257fdb7a22d9',\n",
       " 'example': False}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#unpacking an event\n",
    "type(e)\n",
    "\n",
    "#unpack generator into list\n",
    "d = []\n",
    "for event in e: \n",
    "    d.append(event)\n",
    "\n",
    "#list all attributes associated with each  event \n",
    "vars(d[0]['messages'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563c198a-d1a4-4700-b7a7-ff5b8e0b25d7",
   "metadata": {},
   "source": [
    "### Streaming tokens\n",
    "\n",
    "We often want to stream more than graph state.\n",
    "\n",
    "In particular, with chat model calls it is common to stream the tokens as they are generated.\n",
    "\n",
    "We can do this [using the `.astream_events` method](https://langchain-ai.github.io/langgraph/how-tos/streaming-from-final-node/#stream-outputs-from-the-final-node), which streams back events as they happen inside nodes!\n",
    "\n",
    "Each event is a dict with a few keys:\n",
    " \n",
    "* `event`: This is the type of event that is being emitted. \n",
    "* `name`: This is the name of event.\n",
    "* `data`: This is the data associated with the event.\n",
    "* `metadata`: Contains`langgraph_node`, the node emitting the event.\n",
    "\n",
    "Let's have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6df8cd43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_chain_start', 'data': {'input': {'messages': [HumanMessage(content='Tell me about the 49ers NFL team', additional_kwargs={}, response_metadata={})]}}, 'name': 'LangGraph', 'tags': [], 'run_id': '6810397c-6ff5-454b-adb0-4523378c5a8e', 'metadata': {'thread_id': '3'}, 'parent_ids': []}\n",
      "{'event': 'on_chain_start', 'data': {'input': {'messages': [HumanMessage(content='Tell me about the 49ers NFL team', additional_kwargs={}, response_metadata={}, id='787b888b-fbc6-4573-83eb-34502e650dc8')]}}, 'name': 'conversation', 'tags': ['graph:step:1'], 'run_id': 'b82bd159-9874-4e34-88e4-e58df06530b2', 'metadata': {'thread_id': '3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation',), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17'}, 'parent_ids': ['6810397c-6ff5-454b-adb0-4523378c5a8e']}\n",
      "{'event': 'on_chat_model_start', 'data': {'input': {'messages': [[HumanMessage(content='Tell me about the 49ers NFL team', additional_kwargs={}, response_metadata={}, id='787b888b-fbc6-4573-83eb-34502e650dc8')]]}}, 'name': 'ChatAnthropic', 'tags': ['seq:step:1'], 'run_id': 'c3d21cb0-49a3-4899-8ede-3332cea7d4b4', 'metadata': {'thread_id': '3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation',), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 4000}, 'parent_ids': ['6810397c-6ff5-454b-adb0-4523378c5a8e', 'b82bd159-9874-4e34-88e4-e58df06530b2']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_name': 'claude-3-haiku-20240307'}, id='run--c3d21cb0-49a3-4899-8ede-3332cea7d4b4', usage_metadata={'input_tokens': 16, 'output_tokens': 1, 'total_tokens': 17, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})}, 'run_id': 'c3d21cb0-49a3-4899-8ede-3332cea7d4b4', 'name': 'ChatAnthropic', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation',), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 4000}, 'parent_ids': ['6810397c-6ff5-454b-adb0-4523378c5a8e', 'b82bd159-9874-4e34-88e4-e58df06530b2']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='Here', additional_kwargs={}, response_metadata={}, id='run--c3d21cb0-49a3-4899-8ede-3332cea7d4b4')}, 'run_id': 'c3d21cb0-49a3-4899-8ede-3332cea7d4b4', 'name': 'ChatAnthropic', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation',), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 4000}, 'parent_ids': ['6810397c-6ff5-454b-adb0-4523378c5a8e', 'b82bd159-9874-4e34-88e4-e58df06530b2']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' are some key facts', additional_kwargs={}, response_metadata={}, id='run--c3d21cb0-49a3-4899-8ede-3332cea7d4b4')}, 'run_id': 'c3d21cb0-49a3-4899-8ede-3332cea7d4b4', 'name': 'ChatAnthropic', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation',), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 4000}, 'parent_ids': ['6810397c-6ff5-454b-adb0-4523378c5a8e', 'b82bd159-9874-4e34-88e4-e58df06530b2']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' about the San Francisco 49ers NFL', additional_kwargs={}, response_metadata={}, id='run--c3d21cb0-49a3-4899-8ede-3332cea7d4b4')}, 'run_id': 'c3d21cb0-49a3-4899-8ede-3332cea7d4b4', 'name': 'ChatAnthropic', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation',), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 4000}, 'parent_ids': ['6810397c-6ff5-454b-adb0-4523378c5a8e', 'b82bd159-9874-4e34-88e4-e58df06530b2']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' team:\\n\\n- The 49ers are', additional_kwargs={}, response_metadata={}, id='run--c3d21cb0-49a3-4899-8ede-3332cea7d4b4')}, 'run_id': 'c3d21cb0-49a3-4899-8ede-3332cea7d4b4', 'name': 'ChatAnthropic', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation',), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 4000}, 'parent_ids': ['6810397c-6ff5-454b-adb0-4523378c5a8e', 'b82bd159-9874-4e34-88e4-e58df06530b2']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' based in Santa Clara, California an', additional_kwargs={}, response_metadata={}, id='run--c3d21cb0-49a3-4899-8ede-3332cea7d4b4')}, 'run_id': 'c3d21cb0-49a3-4899-8ede-3332cea7d4b4', 'name': 'ChatAnthropic', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation',), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 4000}, 'parent_ids': ['6810397c-6ff5-454b-adb0-4523378c5a8e', 'b82bd159-9874-4e34-88e4-e58df06530b2']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='d play their home games at Levi', additional_kwargs={}, response_metadata={}, id='run--c3d21cb0-49a3-4899-8ede-3332cea7d4b4')}, 'run_id': 'c3d21cb0-49a3-4899-8ede-3332cea7d4b4', 'name': 'ChatAnthropic', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation',), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 4000}, 'parent_ids': ['6810397c-6ff5-454b-adb0-4523378c5a8e', 'b82bd159-9874-4e34-88e4-e58df06530b2']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=\"'s Stadium.\\n\\n- They are members\", additional_kwargs={}, response_metadata={}, id='run--c3d21cb0-49a3-4899-8ede-3332cea7d4b4')}, 'run_id': 'c3d21cb0-49a3-4899-8ede-3332cea7d4b4', 'name': 'ChatAnthropic', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation',), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 4000}, 'parent_ids': ['6810397c-6ff5-454b-adb0-4523378c5a8e', 'b82bd159-9874-4e34-88e4-e58df06530b2']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' of the National Football Conference (NFC)', additional_kwargs={}, response_metadata={}, id='run--c3d21cb0-49a3-4899-8ede-3332cea7d4b4')}, 'run_id': 'c3d21cb0-49a3-4899-8ede-3332cea7d4b4', 'name': 'ChatAnthropic', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation',), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 4000}, 'parent_ids': ['6810397c-6ff5-454b-adb0-4523378c5a8e', 'b82bd159-9874-4e34-88e4-e58df06530b2']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' West division in the National Football League (NFL', additional_kwargs={}, response_metadata={}, id='run--c3d21cb0-49a3-4899-8ede-3332cea7d4b4')}, 'run_id': 'c3d21cb0-49a3-4899-8ede-3332cea7d4b4', 'name': 'ChatAnthropic', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation',), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 4000}, 'parent_ids': ['6810397c-6ff5-454b-adb0-4523378c5a8e', 'b82bd159-9874-4e34-88e4-e58df06530b2']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=').\\n\\n- The 49ers were', additional_kwargs={}, response_metadata={}, id='run--c3d21cb0-49a3-4899-8ede-3332cea7d4b4')}, 'run_id': 'c3d21cb0-49a3-4899-8ede-3332cea7d4b4', 'name': 'ChatAnthropic', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation',), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 4000}, 'parent_ids': ['6810397c-6ff5-454b-adb0-4523378c5a8e', 'b82bd159-9874-4e34-88e4-e58df06530b2']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' founded in 1946 as', additional_kwargs={}, response_metadata={}, id='run--c3d21cb0-49a3-4899-8ede-3332cea7d4b4')}, 'run_id': 'c3d21cb0-49a3-4899-8ede-3332cea7d4b4', 'name': 'ChatAnthropic', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation',), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 4000}, 'parent_ids': ['6810397c-6ff5-454b-adb0-4523378c5a8e', 'b82bd159-9874-4e34-88e4-e58df06530b2']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' a charter member of the All-America Football Conference', additional_kwargs={}, response_metadata={}, id='run--c3d21cb0-49a3-4899-8ede-3332cea7d4b4')}, 'run_id': 'c3d21cb0-49a3-4899-8ede-3332cea7d4b4', 'name': 'ChatAnthropic', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation',), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 4000}, 'parent_ids': ['6810397c-6ff5-454b-adb0-4523378c5a8e', 'b82bd159-9874-4e34-88e4-e58df06530b2']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' (AAFC)', additional_kwargs={}, response_metadata={}, id='run--c3d21cb0-49a3-4899-8ede-3332cea7d4b4')}, 'run_id': 'c3d21cb0-49a3-4899-8ede-3332cea7d4b4', 'name': 'ChatAnthropic', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation',), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 4000}, 'parent_ids': ['6810397c-6ff5-454b-adb0-4523378c5a8e', 'b82bd159-9874-4e34-88e4-e58df06530b2']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' and joined the NFL in 1950', additional_kwargs={}, response_metadata={}, id='run--c3d21cb0-49a3-4899-8ede-3332cea7d4b4')}, 'run_id': 'c3d21cb0-49a3-4899-8ede-3332cea7d4b4', 'name': 'ChatAnthropic', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation',), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 4000}, 'parent_ids': ['6810397c-6ff5-454b-adb0-4523378c5a8e', 'b82bd159-9874-4e34-88e4-e58df06530b2']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='.\\n\\n- They have won 5', additional_kwargs={}, response_metadata={}, id='run--c3d21cb0-49a3-4899-8ede-3332cea7d4b4')}, 'run_id': 'c3d21cb0-49a3-4899-8ede-3332cea7d4b4', 'name': 'ChatAnthropic', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation',), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 4000}, 'parent_ids': ['6810397c-6ff5-454b-adb0-4523378c5a8e', 'b82bd159-9874-4e34-88e4-e58df06530b2']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' Super Bowl championships, which', additional_kwargs={}, response_metadata={}, id='run--c3d21cb0-49a3-4899-8ede-3332cea7d4b4')}, 'run_id': 'c3d21cb0-49a3-4899-8ede-3332cea7d4b4', 'name': 'ChatAnthropic', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation',), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 4000}, 'parent_ids': ['6810397c-6ff5-454b-adb0-4523378c5a8e', 'b82bd159-9874-4e34-88e4-e58df06530b2']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' ties them for the second-', additional_kwargs={}, response_metadata={}, id='run--c3d21cb0-49a3-4899-8ede-3332cea7d4b4')}, 'run_id': 'c3d21cb0-49a3-4899-8ede-3332cea7d4b4', 'name': 'ChatAnthropic', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation',), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 4000}, 'parent_ids': ['6810397c-6ff5-454b-adb0-4523378c5a8e', 'b82bd159-9874-4e34-88e4-e58df06530b2']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='most Super Bowl wins along', additional_kwargs={}, response_metadata={}, id='run--c3d21cb0-49a3-4899-8ede-3332cea7d4b4')}, 'run_id': 'c3d21cb0-49a3-4899-8ede-3332cea7d4b4', 'name': 'ChatAnthropic', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation',), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 4000}, 'parent_ids': ['6810397c-6ff5-454b-adb0-4523378c5a8e', 'b82bd159-9874-4e34-88e4-e58df06530b2']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' with the Dallas Cowboys. Their', additional_kwargs={}, response_metadata={}, id='run--c3d21cb0-49a3-4899-8ede-3332cea7d4b4')}, 'run_id': 'c3d21cb0-49a3-4899-8ede-3332cea7d4b4', 'name': 'ChatAnthropic', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation',), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 4000}, 'parent_ids': ['6810397c-6ff5-454b-adb0-4523378c5a8e', 'b82bd159-9874-4e34-88e4-e58df06530b2']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' Super Bowl wins came in 1981', additional_kwargs={}, response_metadata={}, id='run--c3d21cb0-49a3-4899-8ede-3332cea7d4b4')}, 'run_id': 'c3d21cb0-49a3-4899-8ede-3332cea7d4b4', 'name': 'ChatAnthropic', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation',), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 4000}, 'parent_ids': ['6810397c-6ff5-454b-adb0-4523378c5a8e', 'b82bd159-9874-4e34-88e4-e58df06530b2']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=', 1984, 1988', additional_kwargs={}, response_metadata={}, id='run--c3d21cb0-49a3-4899-8ede-3332cea7d4b4')}, 'run_id': 'c3d21cb0-49a3-4899-8ede-3332cea7d4b4', 'name': 'ChatAnthropic', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation',), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 4000}, 'parent_ids': ['6810397c-6ff5-454b-adb0-4523378c5a8e', 'b82bd159-9874-4e34-88e4-e58df06530b2']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=', 1989, and 1', additional_kwargs={}, response_metadata={}, id='run--c3d21cb0-49a3-4899-8ede-3332cea7d4b4')}, 'run_id': 'c3d21cb0-49a3-4899-8ede-3332cea7d4b4', 'name': 'ChatAnthropic', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation',), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 4000}, 'parent_ids': ['6810397c-6ff5-454b-adb0-4523378c5a8e', 'b82bd159-9874-4e34-88e4-e58df06530b2']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='994.\\n\\n- Some of their most famous', additional_kwargs={}, response_metadata={}, id='run--c3d21cb0-49a3-4899-8ede-3332cea7d4b4')}, 'run_id': 'c3d21cb0-49a3-4899-8ede-3332cea7d4b4', 'name': 'ChatAnthropic', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation',), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 4000}, 'parent_ids': ['6810397c-6ff5-454b-adb0-4523378c5a8e', 'b82bd159-9874-4e34-88e4-e58df06530b2']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' players include quarterbacks Joe Montana and Steve Young, wide receiver', additional_kwargs={}, response_metadata={}, id='run--c3d21cb0-49a3-4899-8ede-3332cea7d4b4')}, 'run_id': 'c3d21cb0-49a3-4899-8ede-3332cea7d4b4', 'name': 'ChatAnthropic', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation',), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 4000}, 'parent_ids': ['6810397c-6ff5-454b-adb0-4523378c5a8e', 'b82bd159-9874-4e34-88e4-e58df06530b2']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' Jerry Rice, and linebacker Patrick Willis.\\n\\n-', additional_kwargs={}, response_metadata={}, id='run--c3d21cb0-49a3-4899-8ede-3332cea7d4b4')}, 'run_id': 'c3d21cb0-49a3-4899-8ede-3332cea7d4b4', 'name': 'ChatAnthropic', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation',), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 4000}, 'parent_ids': ['6810397c-6ff5-454b-adb0-4523378c5a8e', 'b82bd159-9874-4e34-88e4-e58df06530b2']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' The 49ers had a dominant run in the ', additional_kwargs={}, response_metadata={}, id='run--c3d21cb0-49a3-4899-8ede-3332cea7d4b4')}, 'run_id': 'c3d21cb0-49a3-4899-8ede-3332cea7d4b4', 'name': 'ChatAnthropic', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation',), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 4000}, 'parent_ids': ['6810397c-6ff5-454b-adb0-4523378c5a8e', 'b82bd159-9874-4e34-88e4-e58df06530b2']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='1980s and early 1990s', additional_kwargs={}, response_metadata={}, id='run--c3d21cb0-49a3-4899-8ede-3332cea7d4b4')}, 'run_id': 'c3d21cb0-49a3-4899-8ede-3332cea7d4b4', 'name': 'ChatAnthropic', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation',), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 4000}, 'parent_ids': ['6810397c-6ff5-454b-adb0-4523378c5a8e', 'b82bd159-9874-4e34-88e4-e58df06530b2']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=', making the playoffs 16 times in ', additional_kwargs={}, response_metadata={}, id='run--c3d21cb0-49a3-4899-8ede-3332cea7d4b4')}, 'run_id': 'c3d21cb0-49a3-4899-8ede-3332cea7d4b4', 'name': 'ChatAnthropic', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation',), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 4000}, 'parent_ids': ['6810397c-6ff5-454b-adb0-4523378c5a8e', 'b82bd159-9874-4e34-88e4-e58df06530b2']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='18 seasons and winning 5 Super Bowls.\\n\\n- In', additional_kwargs={}, response_metadata={}, id='run--c3d21cb0-49a3-4899-8ede-3332cea7d4b4')}, 'run_id': 'c3d21cb0-49a3-4899-8ede-3332cea7d4b4', 'name': 'ChatAnthropic', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation',), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 4000}, 'parent_ids': ['6810397c-6ff5-454b-adb0-4523378c5a8e', 'b82bd159-9874-4e34-88e4-e58df06530b2']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' recent years, the 49ers have ha', additional_kwargs={}, response_metadata={}, id='run--c3d21cb0-49a3-4899-8ede-3332cea7d4b4')}, 'run_id': 'c3d21cb0-49a3-4899-8ede-3332cea7d4b4', 'name': 'ChatAnthropic', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation',), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 4000}, 'parent_ids': ['6810397c-6ff5-454b-adb0-4523378c5a8e', 'b82bd159-9874-4e34-88e4-e58df06530b2']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='d some ups and downs, but they made', additional_kwargs={}, response_metadata={}, id='run--c3d21cb0-49a3-4899-8ede-3332cea7d4b4')}, 'run_id': 'c3d21cb0-49a3-4899-8ede-3332cea7d4b4', 'name': 'ChatAnthropic', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation',), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 4000}, 'parent_ids': ['6810397c-6ff5-454b-adb0-4523378c5a8e', 'b82bd159-9874-4e34-88e4-e58df06530b2']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' it to the Super Bowl in 2012', additional_kwargs={}, response_metadata={}, id='run--c3d21cb0-49a3-4899-8ede-3332cea7d4b4')}, 'run_id': 'c3d21cb0-49a3-4899-8ede-3332cea7d4b4', 'name': 'ChatAnthropic', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation',), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 4000}, 'parent_ids': ['6810397c-6ff5-454b-adb0-4523378c5a8e', 'b82bd159-9874-4e34-88e4-e58df06530b2']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' and 2019 before', additional_kwargs={}, response_metadata={}, id='run--c3d21cb0-49a3-4899-8ede-3332cea7d4b4')}, 'run_id': 'c3d21cb0-49a3-4899-8ede-3332cea7d4b4', 'name': 'ChatAnthropic', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation',), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 4000}, 'parent_ids': ['6810397c-6ff5-454b-adb0-4523378c5a8e', 'b82bd159-9874-4e34-88e4-e58df06530b2']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' losing.\\n\\n- The 49ers have', additional_kwargs={}, response_metadata={}, id='run--c3d21cb0-49a3-4899-8ede-3332cea7d4b4')}, 'run_id': 'c3d21cb0-49a3-4899-8ede-3332cea7d4b4', 'name': 'ChatAnthropic', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation',), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 4000}, 'parent_ids': ['6810397c-6ff5-454b-adb0-4523378c5a8e', 'b82bd159-9874-4e34-88e4-e58df06530b2']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' a strong fan base and are considered one of the', additional_kwargs={}, response_metadata={}, id='run--c3d21cb0-49a3-4899-8ede-3332cea7d4b4')}, 'run_id': 'c3d21cb0-49a3-4899-8ede-3332cea7d4b4', 'name': 'ChatAnthropic', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation',), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 4000}, 'parent_ids': ['6810397c-6ff5-454b-adb0-4523378c5a8e', 'b82bd159-9874-4e34-88e4-e58df06530b2']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' most successful and iconic franchises in NFL', additional_kwargs={}, response_metadata={}, id='run--c3d21cb0-49a3-4899-8ede-3332cea7d4b4')}, 'run_id': 'c3d21cb0-49a3-4899-8ede-3332cea7d4b4', 'name': 'ChatAnthropic', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation',), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 4000}, 'parent_ids': ['6810397c-6ff5-454b-adb0-4523378c5a8e', 'b82bd159-9874-4e34-88e4-e58df06530b2']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' history.', additional_kwargs={}, response_metadata={}, id='run--c3d21cb0-49a3-4899-8ede-3332cea7d4b4')}, 'run_id': 'c3d21cb0-49a3-4899-8ede-3332cea7d4b4', 'name': 'ChatAnthropic', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation',), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 4000}, 'parent_ids': ['6810397c-6ff5-454b-adb0-4523378c5a8e', 'b82bd159-9874-4e34-88e4-e58df06530b2']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'stop_reason': 'end_turn', 'stop_sequence': None}, id='run--c3d21cb0-49a3-4899-8ede-3332cea7d4b4', usage_metadata={'input_tokens': 0, 'output_tokens': 299, 'total_tokens': 299, 'input_token_details': {}})}, 'run_id': 'c3d21cb0-49a3-4899-8ede-3332cea7d4b4', 'name': 'ChatAnthropic', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation',), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 4000}, 'parent_ids': ['6810397c-6ff5-454b-adb0-4523378c5a8e', 'b82bd159-9874-4e34-88e4-e58df06530b2']}\n",
      "{'event': 'on_chat_model_end', 'data': {'output': AIMessage(content=\"Here are some key facts about the San Francisco 49ers NFL team:\\n\\n- The 49ers are based in Santa Clara, California and play their home games at Levi's Stadium.\\n\\n- They are members of the National Football Conference (NFC) West division in the National Football League (NFL).\\n\\n- The 49ers were founded in 1946 as a charter member of the All-America Football Conference (AAFC) and joined the NFL in 1950.\\n\\n- They have won 5 Super Bowl championships, which ties them for the second-most Super Bowl wins along with the Dallas Cowboys. Their Super Bowl wins came in 1981, 1984, 1988, 1989, and 1994.\\n\\n- Some of their most famous players include quarterbacks Joe Montana and Steve Young, wide receiver Jerry Rice, and linebacker Patrick Willis.\\n\\n- The 49ers had a dominant run in the 1980s and early 1990s, making the playoffs 16 times in 18 seasons and winning 5 Super Bowls.\\n\\n- In recent years, the 49ers have had some ups and downs, but they made it to the Super Bowl in 2012 and 2019 before losing.\\n\\n- The 49ers have a strong fan base and are considered one of the most successful and iconic franchises in NFL history.\", additional_kwargs={}, response_metadata={'model_name': 'claude-3-haiku-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None}, id='run--c3d21cb0-49a3-4899-8ede-3332cea7d4b4', usage_metadata={'input_tokens': 16, 'output_tokens': 300, 'total_tokens': 316, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}), 'input': {'messages': [[HumanMessage(content='Tell me about the 49ers NFL team', additional_kwargs={}, response_metadata={}, id='787b888b-fbc6-4573-83eb-34502e650dc8')]]}}, 'run_id': 'c3d21cb0-49a3-4899-8ede-3332cea7d4b4', 'name': 'ChatAnthropic', 'tags': ['seq:step:1'], 'metadata': {'thread_id': '3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation',), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 4000}, 'parent_ids': ['6810397c-6ff5-454b-adb0-4523378c5a8e', 'b82bd159-9874-4e34-88e4-e58df06530b2']}\n",
      "{'event': 'on_chain_start', 'data': {'input': {'messages': [HumanMessage(content='Tell me about the 49ers NFL team', additional_kwargs={}, response_metadata={}, id='787b888b-fbc6-4573-83eb-34502e650dc8'), AIMessage(content=\"Here are some key facts about the San Francisco 49ers NFL team:\\n\\n- The 49ers are based in Santa Clara, California and play their home games at Levi's Stadium.\\n\\n- They are members of the National Football Conference (NFC) West division in the National Football League (NFL).\\n\\n- The 49ers were founded in 1946 as a charter member of the All-America Football Conference (AAFC) and joined the NFL in 1950.\\n\\n- They have won 5 Super Bowl championships, which ties them for the second-most Super Bowl wins along with the Dallas Cowboys. Their Super Bowl wins came in 1981, 1984, 1988, 1989, and 1994.\\n\\n- Some of their most famous players include quarterbacks Joe Montana and Steve Young, wide receiver Jerry Rice, and linebacker Patrick Willis.\\n\\n- The 49ers had a dominant run in the 1980s and early 1990s, making the playoffs 16 times in 18 seasons and winning 5 Super Bowls.\\n\\n- In recent years, the 49ers have had some ups and downs, but they made it to the Super Bowl in 2012 and 2019 before losing.\\n\\n- The 49ers have a strong fan base and are considered one of the most successful and iconic franchises in NFL history.\", additional_kwargs={}, response_metadata={'model_name': 'claude-3-haiku-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None}, id='run--c3d21cb0-49a3-4899-8ede-3332cea7d4b4', usage_metadata={'input_tokens': 16, 'output_tokens': 300, 'total_tokens': 316, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})]}}, 'name': 'should_continue', 'tags': ['seq:step:3'], 'run_id': '3721ae18-68ff-4644-942c-1369050b2666', 'metadata': {'thread_id': '3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation',), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17'}, 'parent_ids': ['6810397c-6ff5-454b-adb0-4523378c5a8e', 'b82bd159-9874-4e34-88e4-e58df06530b2']}\n",
      "{'event': 'on_chain_end', 'data': {'output': '__end__', 'input': {'messages': [HumanMessage(content='Tell me about the 49ers NFL team', additional_kwargs={}, response_metadata={}, id='787b888b-fbc6-4573-83eb-34502e650dc8'), AIMessage(content=\"Here are some key facts about the San Francisco 49ers NFL team:\\n\\n- The 49ers are based in Santa Clara, California and play their home games at Levi's Stadium.\\n\\n- They are members of the National Football Conference (NFC) West division in the National Football League (NFL).\\n\\n- The 49ers were founded in 1946 as a charter member of the All-America Football Conference (AAFC) and joined the NFL in 1950.\\n\\n- They have won 5 Super Bowl championships, which ties them for the second-most Super Bowl wins along with the Dallas Cowboys. Their Super Bowl wins came in 1981, 1984, 1988, 1989, and 1994.\\n\\n- Some of their most famous players include quarterbacks Joe Montana and Steve Young, wide receiver Jerry Rice, and linebacker Patrick Willis.\\n\\n- The 49ers had a dominant run in the 1980s and early 1990s, making the playoffs 16 times in 18 seasons and winning 5 Super Bowls.\\n\\n- In recent years, the 49ers have had some ups and downs, but they made it to the Super Bowl in 2012 and 2019 before losing.\\n\\n- The 49ers have a strong fan base and are considered one of the most successful and iconic franchises in NFL history.\", additional_kwargs={}, response_metadata={'model_name': 'claude-3-haiku-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None}, id='run--c3d21cb0-49a3-4899-8ede-3332cea7d4b4', usage_metadata={'input_tokens': 16, 'output_tokens': 300, 'total_tokens': 316, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})]}}, 'run_id': '3721ae18-68ff-4644-942c-1369050b2666', 'name': 'should_continue', 'tags': ['seq:step:3'], 'metadata': {'thread_id': '3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation',), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17'}, 'parent_ids': ['6810397c-6ff5-454b-adb0-4523378c5a8e', 'b82bd159-9874-4e34-88e4-e58df06530b2']}\n",
      "{'event': 'on_chain_stream', 'run_id': 'b82bd159-9874-4e34-88e4-e58df06530b2', 'name': 'conversation', 'tags': ['graph:step:1'], 'metadata': {'thread_id': '3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation',), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17'}, 'data': {'chunk': {'messages': AIMessage(content=\"Here are some key facts about the San Francisco 49ers NFL team:\\n\\n- The 49ers are based in Santa Clara, California and play their home games at Levi's Stadium.\\n\\n- They are members of the National Football Conference (NFC) West division in the National Football League (NFL).\\n\\n- The 49ers were founded in 1946 as a charter member of the All-America Football Conference (AAFC) and joined the NFL in 1950.\\n\\n- They have won 5 Super Bowl championships, which ties them for the second-most Super Bowl wins along with the Dallas Cowboys. Their Super Bowl wins came in 1981, 1984, 1988, 1989, and 1994.\\n\\n- Some of their most famous players include quarterbacks Joe Montana and Steve Young, wide receiver Jerry Rice, and linebacker Patrick Willis.\\n\\n- The 49ers had a dominant run in the 1980s and early 1990s, making the playoffs 16 times in 18 seasons and winning 5 Super Bowls.\\n\\n- In recent years, the 49ers have had some ups and downs, but they made it to the Super Bowl in 2012 and 2019 before losing.\\n\\n- The 49ers have a strong fan base and are considered one of the most successful and iconic franchises in NFL history.\", additional_kwargs={}, response_metadata={'model_name': 'claude-3-haiku-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None}, id='run--c3d21cb0-49a3-4899-8ede-3332cea7d4b4', usage_metadata={'input_tokens': 16, 'output_tokens': 300, 'total_tokens': 316, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})}}, 'parent_ids': ['6810397c-6ff5-454b-adb0-4523378c5a8e']}\n",
      "{'event': 'on_chain_end', 'data': {'output': {'messages': AIMessage(content=\"Here are some key facts about the San Francisco 49ers NFL team:\\n\\n- The 49ers are based in Santa Clara, California and play their home games at Levi's Stadium.\\n\\n- They are members of the National Football Conference (NFC) West division in the National Football League (NFL).\\n\\n- The 49ers were founded in 1946 as a charter member of the All-America Football Conference (AAFC) and joined the NFL in 1950.\\n\\n- They have won 5 Super Bowl championships, which ties them for the second-most Super Bowl wins along with the Dallas Cowboys. Their Super Bowl wins came in 1981, 1984, 1988, 1989, and 1994.\\n\\n- Some of their most famous players include quarterbacks Joe Montana and Steve Young, wide receiver Jerry Rice, and linebacker Patrick Willis.\\n\\n- The 49ers had a dominant run in the 1980s and early 1990s, making the playoffs 16 times in 18 seasons and winning 5 Super Bowls.\\n\\n- In recent years, the 49ers have had some ups and downs, but they made it to the Super Bowl in 2012 and 2019 before losing.\\n\\n- The 49ers have a strong fan base and are considered one of the most successful and iconic franchises in NFL history.\", additional_kwargs={}, response_metadata={'model_name': 'claude-3-haiku-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None}, id='run--c3d21cb0-49a3-4899-8ede-3332cea7d4b4', usage_metadata={'input_tokens': 16, 'output_tokens': 300, 'total_tokens': 316, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})}, 'input': {'messages': [HumanMessage(content='Tell me about the 49ers NFL team', additional_kwargs={}, response_metadata={}, id='787b888b-fbc6-4573-83eb-34502e650dc8')]}}, 'run_id': 'b82bd159-9874-4e34-88e4-e58df06530b2', 'name': 'conversation', 'tags': ['graph:step:1'], 'metadata': {'thread_id': '3', 'langgraph_step': 1, 'langgraph_node': 'conversation', 'langgraph_triggers': ('branch:to:conversation',), 'langgraph_path': ('__pregel_pull', 'conversation'), 'langgraph_checkpoint_ns': 'conversation:966bf1cd-37e8-47ca-d6ec-fd221f3f3b17'}, 'parent_ids': ['6810397c-6ff5-454b-adb0-4523378c5a8e']}\n",
      "{'event': 'on_chain_stream', 'run_id': '6810397c-6ff5-454b-adb0-4523378c5a8e', 'name': 'LangGraph', 'tags': [], 'metadata': {'thread_id': '3'}, 'data': {'chunk': {'conversation': {'messages': AIMessage(content=\"Here are some key facts about the San Francisco 49ers NFL team:\\n\\n- The 49ers are based in Santa Clara, California and play their home games at Levi's Stadium.\\n\\n- They are members of the National Football Conference (NFC) West division in the National Football League (NFL).\\n\\n- The 49ers were founded in 1946 as a charter member of the All-America Football Conference (AAFC) and joined the NFL in 1950.\\n\\n- They have won 5 Super Bowl championships, which ties them for the second-most Super Bowl wins along with the Dallas Cowboys. Their Super Bowl wins came in 1981, 1984, 1988, 1989, and 1994.\\n\\n- Some of their most famous players include quarterbacks Joe Montana and Steve Young, wide receiver Jerry Rice, and linebacker Patrick Willis.\\n\\n- The 49ers had a dominant run in the 1980s and early 1990s, making the playoffs 16 times in 18 seasons and winning 5 Super Bowls.\\n\\n- In recent years, the 49ers have had some ups and downs, but they made it to the Super Bowl in 2012 and 2019 before losing.\\n\\n- The 49ers have a strong fan base and are considered one of the most successful and iconic franchises in NFL history.\", additional_kwargs={}, response_metadata={'model_name': 'claude-3-haiku-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None}, id='run--c3d21cb0-49a3-4899-8ede-3332cea7d4b4', usage_metadata={'input_tokens': 16, 'output_tokens': 300, 'total_tokens': 316, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})}}}, 'parent_ids': []}\n",
      "{'event': 'on_chain_end', 'data': {'output': {'messages': [HumanMessage(content='Tell me about the 49ers NFL team', additional_kwargs={}, response_metadata={}, id='787b888b-fbc6-4573-83eb-34502e650dc8'), AIMessage(content=\"Here are some key facts about the San Francisco 49ers NFL team:\\n\\n- The 49ers are based in Santa Clara, California and play their home games at Levi's Stadium.\\n\\n- They are members of the National Football Conference (NFC) West division in the National Football League (NFL).\\n\\n- The 49ers were founded in 1946 as a charter member of the All-America Football Conference (AAFC) and joined the NFL in 1950.\\n\\n- They have won 5 Super Bowl championships, which ties them for the second-most Super Bowl wins along with the Dallas Cowboys. Their Super Bowl wins came in 1981, 1984, 1988, 1989, and 1994.\\n\\n- Some of their most famous players include quarterbacks Joe Montana and Steve Young, wide receiver Jerry Rice, and linebacker Patrick Willis.\\n\\n- The 49ers had a dominant run in the 1980s and early 1990s, making the playoffs 16 times in 18 seasons and winning 5 Super Bowls.\\n\\n- In recent years, the 49ers have had some ups and downs, but they made it to the Super Bowl in 2012 and 2019 before losing.\\n\\n- The 49ers have a strong fan base and are considered one of the most successful and iconic franchises in NFL history.\", additional_kwargs={}, response_metadata={'model_name': 'claude-3-haiku-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None}, id='run--c3d21cb0-49a3-4899-8ede-3332cea7d4b4', usage_metadata={'input_tokens': 16, 'output_tokens': 300, 'total_tokens': 316, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})]}}, 'run_id': '6810397c-6ff5-454b-adb0-4523378c5a8e', 'name': 'LangGraph', 'tags': [], 'metadata': {'thread_id': '3'}, 'parent_ids': []}\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the 49ers NFL team\")\n",
    "\n",
    "# Stream each token as it is generated\n",
    "async for event in graph.astream_events({\"messages\": [input_message]},\n",
    "                                         config, version=\"v2\"):\n",
    "    \n",
    "    print(event)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ae8c7a6-c6e7-4cef-ac9f-190d2f4dd763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node: . Type: on_chain_start. Name: LangGraph\n",
      "                             \n",
      "Node: conversation. Type: on_chain_start. Name: conversation\n",
      "                             \n",
      "Node: conversation. Type: on_chat_model_start. Name: ChatAnthropic\n",
      "                             \n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "                             \n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "                             \n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "                             \n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "                             \n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "                             \n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "                             \n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "                             \n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "                             \n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "                             \n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "                             \n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "                             \n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "                             \n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "                             \n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "                             \n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "                             \n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "                             \n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "                             \n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "                             \n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "                             \n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "                             \n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "                             \n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "                             \n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "                             \n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "                             \n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "                             \n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "                             \n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "                             \n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "                             \n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "                             \n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "                             \n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "                             \n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "                             \n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "                             \n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "                             \n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "                             \n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "                             \n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "                             \n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "                             \n",
      "Node: conversation. Type: on_chat_model_end. Name: ChatAnthropic\n",
      "                             \n",
      "Node: conversation. Type: on_chain_start. Name: should_continue\n",
      "                             \n",
      "Node: conversation. Type: on_chain_end. Name: should_continue\n",
      "                             \n",
      "Node: conversation. Type: on_chain_stream. Name: conversation\n",
      "                             \n",
      "Node: conversation. Type: on_chain_end. Name: conversation\n",
      "                             \n",
      "Node: . Type: on_chain_stream. Name: LangGraph\n",
      "                             \n",
      "Node: . Type: on_chain_end. Name: LangGraph\n",
      "                             \n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the 49ers NFL team\")\n",
    "\n",
    "# Stream each token as it is generated\n",
    "async for event in graph.astream_events({\"messages\": [input_message]},\n",
    "                                         config, version=\"v2\"):\n",
    "    \n",
    "    print(\n",
    "        f\"\"\"Node: {event['metadata'].get('langgraph_node','')\n",
    "                   }. Type: {event['event']\n",
    "                             }. Name: {event['name']}\n",
    "                             \"\"\"\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b63490f-3d24-4f68-95ca-5320ccb61d2d",
   "metadata": {},
   "source": [
    "The central point is that tokens from chat models within your graph have the `on_chat_model_stream` type.\n",
    "\n",
    "We can use `event['metadata']['langgraph_node']` to select the node to stream from.\n",
    "\n",
    "And we can use `event['data']` to get the actual data for each event, which in this case is an `AIMessageChunk`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc3529f8-3960-4d41-9ed6-373f93183950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_name': 'claude-3-haiku-20240307'}, id='run--2b41a74a-7950-4da5-b82c-7b884d64377d', usage_metadata={'input_tokens': 16, 'output_tokens': 1, 'total_tokens': 17, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})}\n",
      "{'chunk': AIMessageChunk(content='Here', additional_kwargs={}, response_metadata={}, id='run--2b41a74a-7950-4da5-b82c-7b884d64377d')}\n",
      "{'chunk': AIMessageChunk(content=' are some key facts about the San Francisco 49ers NFL', additional_kwargs={}, response_metadata={}, id='run--2b41a74a-7950-4da5-b82c-7b884d64377d')}\n",
      "{'chunk': AIMessageChunk(content=' team:\\n\\n- The 49ers are', additional_kwargs={}, response_metadata={}, id='run--2b41a74a-7950-4da5-b82c-7b884d64377d')}\n",
      "{'chunk': AIMessageChunk(content=' based in Santa Clara, California an', additional_kwargs={}, response_metadata={}, id='run--2b41a74a-7950-4da5-b82c-7b884d64377d')}\n",
      "{'chunk': AIMessageChunk(content='d play their home games at Levi', additional_kwargs={}, response_metadata={}, id='run--2b41a74a-7950-4da5-b82c-7b884d64377d')}\n",
      "{'chunk': AIMessageChunk(content=\"'s Stadium.\\n\\n- They are\", additional_kwargs={}, response_metadata={}, id='run--2b41a74a-7950-4da5-b82c-7b884d64377d')}\n",
      "{'chunk': AIMessageChunk(content=' members of the National Football Conference', additional_kwargs={}, response_metadata={}, id='run--2b41a74a-7950-4da5-b82c-7b884d64377d')}\n",
      "{'chunk': AIMessageChunk(content=' (NFC) West division in the', additional_kwargs={}, response_metadata={}, id='run--2b41a74a-7950-4da5-b82c-7b884d64377d')}\n",
      "{'chunk': AIMessageChunk(content=' National Football League (NFL).\\n\\n- The', additional_kwargs={}, response_metadata={}, id='run--2b41a74a-7950-4da5-b82c-7b884d64377d')}\n",
      "{'chunk': AIMessageChunk(content=' 49ers were founded in 1', additional_kwargs={}, response_metadata={}, id='run--2b41a74a-7950-4da5-b82c-7b884d64377d')}\n",
      "{'chunk': AIMessageChunk(content='946 as a charter member of the', additional_kwargs={}, response_metadata={}, id='run--2b41a74a-7950-4da5-b82c-7b884d64377d')}\n",
      "{'chunk': AIMessageChunk(content=' All-America Football Conference (AA', additional_kwargs={}, response_metadata={}, id='run--2b41a74a-7950-4da5-b82c-7b884d64377d')}\n",
      "{'chunk': AIMessageChunk(content='FC) and joined the NFL', additional_kwargs={}, response_metadata={}, id='run--2b41a74a-7950-4da5-b82c-7b884d64377d')}\n",
      "{'chunk': AIMessageChunk(content=' in 1950.\\n\\n- They', additional_kwargs={}, response_metadata={}, id='run--2b41a74a-7950-4da5-b82c-7b884d64377d')}\n",
      "{'chunk': AIMessageChunk(content=' have won 5 Super Bowl championships', additional_kwargs={}, response_metadata={}, id='run--2b41a74a-7950-4da5-b82c-7b884d64377d')}\n",
      "{'chunk': AIMessageChunk(content=', which ties them for the secon', additional_kwargs={}, response_metadata={}, id='run--2b41a74a-7950-4da5-b82c-7b884d64377d')}\n",
      "{'chunk': AIMessageChunk(content='d-most Super Bowl wins along with the Dallas', additional_kwargs={}, response_metadata={}, id='run--2b41a74a-7950-4da5-b82c-7b884d64377d')}\n",
      "{'chunk': AIMessageChunk(content=' Cowboys. Their Super Bowl wins came in', additional_kwargs={}, response_metadata={}, id='run--2b41a74a-7950-4da5-b82c-7b884d64377d')}\n",
      "{'chunk': AIMessageChunk(content=' 1981, 1984', additional_kwargs={}, response_metadata={}, id='run--2b41a74a-7950-4da5-b82c-7b884d64377d')}\n",
      "{'chunk': AIMessageChunk(content=', 1988, 1989', additional_kwargs={}, response_metadata={}, id='run--2b41a74a-7950-4da5-b82c-7b884d64377d')}\n",
      "{'chunk': AIMessageChunk(content=', and 1994.\\n\\n- Some', additional_kwargs={}, response_metadata={}, id='run--2b41a74a-7950-4da5-b82c-7b884d64377d')}\n",
      "{'chunk': AIMessageChunk(content=' of their most famous players include quarter', additional_kwargs={}, response_metadata={}, id='run--2b41a74a-7950-4da5-b82c-7b884d64377d')}\n",
      "{'chunk': AIMessageChunk(content='backs Joe Montana and Steve Young, wide', additional_kwargs={}, response_metadata={}, id='run--2b41a74a-7950-4da5-b82c-7b884d64377d')}\n",
      "{'chunk': AIMessageChunk(content=' receiver Jerry Rice, and linebacker Patrick', additional_kwargs={}, response_metadata={}, id='run--2b41a74a-7950-4da5-b82c-7b884d64377d')}\n",
      "{'chunk': AIMessageChunk(content=' Willis.\\n\\n- The 49ers', additional_kwargs={}, response_metadata={}, id='run--2b41a74a-7950-4da5-b82c-7b884d64377d')}\n",
      "{'chunk': AIMessageChunk(content=' had a dominant run in the 1980', additional_kwargs={}, response_metadata={}, id='run--2b41a74a-7950-4da5-b82c-7b884d64377d')}\n",
      "{'chunk': AIMessageChunk(content='s and early 1990s, making', additional_kwargs={}, response_metadata={}, id='run--2b41a74a-7950-4da5-b82c-7b884d64377d')}\n",
      "{'chunk': AIMessageChunk(content=' the playoffs 16 times in ', additional_kwargs={}, response_metadata={}, id='run--2b41a74a-7950-4da5-b82c-7b884d64377d')}\n",
      "{'chunk': AIMessageChunk(content='18 seasons and winning 5 ', additional_kwargs={}, response_metadata={}, id='run--2b41a74a-7950-4da5-b82c-7b884d64377d')}\n",
      "{'chunk': AIMessageChunk(content='Super Bowls.\\n\\n- In', additional_kwargs={}, response_metadata={}, id='run--2b41a74a-7950-4da5-b82c-7b884d64377d')}\n",
      "{'chunk': AIMessageChunk(content=' recent years, the 49ers have ha', additional_kwargs={}, response_metadata={}, id='run--2b41a74a-7950-4da5-b82c-7b884d64377d')}\n",
      "{'chunk': AIMessageChunk(content='d some ups and downs, but', additional_kwargs={}, response_metadata={}, id='run--2b41a74a-7950-4da5-b82c-7b884d64377d')}\n",
      "{'chunk': AIMessageChunk(content=' they made it to the Super Bowl', additional_kwargs={}, response_metadata={}, id='run--2b41a74a-7950-4da5-b82c-7b884d64377d')}\n",
      "{'chunk': AIMessageChunk(content=' in 2012 and 2', additional_kwargs={}, response_metadata={}, id='run--2b41a74a-7950-4da5-b82c-7b884d64377d')}\n",
      "{'chunk': AIMessageChunk(content='019 before losing.\\n\\n- The', additional_kwargs={}, response_metadata={}, id='run--2b41a74a-7950-4da5-b82c-7b884d64377d')}\n",
      "{'chunk': AIMessageChunk(content=' 49ers have a strong fan base and are', additional_kwargs={}, response_metadata={}, id='run--2b41a74a-7950-4da5-b82c-7b884d64377d')}\n",
      "{'chunk': AIMessageChunk(content=' considered one of the most successful and iconic', additional_kwargs={}, response_metadata={}, id='run--2b41a74a-7950-4da5-b82c-7b884d64377d')}\n",
      "{'chunk': AIMessageChunk(content=' franchises in NFL history.', additional_kwargs={}, response_metadata={}, id='run--2b41a74a-7950-4da5-b82c-7b884d64377d')}\n",
      "{'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'stop_reason': 'end_turn', 'stop_sequence': None}, id='run--2b41a74a-7950-4da5-b82c-7b884d64377d', usage_metadata={'input_tokens': 0, 'output_tokens': 299, 'total_tokens': 299, 'input_token_details': {}})}\n"
     ]
    }
   ],
   "source": [
    "node_to_stream = 'conversation'\n",
    "config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the 49ers NFL team\")\n",
    "\n",
    "#NOTE: version is just a flag to indicate the version of the API you are using\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "\n",
    "    # Get chat model tokens from a particular node \n",
    "    # NOTE: this is a hack to get the tokens from the conversation node\n",
    "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == node_to_stream:\n",
    "        print(event[\"data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226e569a-76c3-43d8-8f89-3ae687efde1c",
   "metadata": {},
   "source": [
    "As you see above, just use the `chunk` key to get the `AIMessageChunk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3aeae53d-6dcf-40d0-a0c6-c40de492cc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Here| are some key facts about the San Francisco| 49ers NFL team:\n",
      "\n",
      "-| The 49ers are based in Santa| Clara, California and play their home games| at Levi's Stadium.|\n",
      "\n",
      "- They are members of the National Football| Conference (NFC) West division in the| National Football League (NFL).\n",
      "\n",
      "- The| 49ers were founded in 1|946 as a charter member of the| All-America Football Conference (AA|FC) and joined the NFL| in 1950.\n",
      "\n",
      "- They| have won 5 Super Bowl championships|, which ties them for the secon|d-most Super Bowl wins along with the Dallas| Cowboys. Their Super Bowl wins came in| 1981, 1984|, 1988, 1989|, and 1994.\n",
      "\n",
      "- Some| of their most famous players include quarter|backs Joe Montana and Steve Young, wide| receiver Jerry Rice, and linebacker Patrick Willis.\n",
      "\n",
      "-| The 49ers had a dominant run in the |1980s and early 1990s|, making the playoffs 16| times in 18 seasons an|d winning 5 Super Bowls|.\n",
      "\n",
      "- In recent| years, the 49ers have ha|d some ups and downs, but they made| it to the Super Bowl in 2012| and 2019 before| losing.\n",
      "\n",
      "- The 49ers have| a strong fan base and are considered one of the| most successful and iconic franchises in NFL| history.||"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"5\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the 49ers NFL team\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    # Get chat model tokens from a particular node \n",
    "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == node_to_stream:\n",
    "        data = event[\"data\"]\n",
    "        print(data[\"chunk\"].content, end=\"|\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5826e4d8-846b-4f6c-a5c1-e781d43022db",
   "metadata": {},
   "source": [
    "### Streaming with LangGraph API\n",
    "\n",
    "**⚠️ DISCLAIMER**\n",
    "\n",
    "Since the filming of these videos, we've updated Studio so that it can be run locally and opened in your browser. This is now the preferred way to run Studio (rather than using the Desktop App as shown in the video). See documentation [here](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/#local-development-server) on the local development server and [here](https://langchain-ai.github.io/langgraph/how-tos/local-studio/#run-the-development-server). To start the local development server, run the following command in your terminal in the `/studio` directory in this module:\n",
    "\n",
    "```\n",
    "langgraph dev\n",
    "```\n",
    "\n",
    "You should see the following output:\n",
    "```\n",
    "- 🚀 API: http://127.0.0.1:2024\n",
    "- 🎨 Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024\n",
    "- 📚 API Docs: http://127.0.0.1:2024/docs\n",
    "```\n",
    "\n",
    "Open your browser and navigate to the Studio UI: `https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024`.\n",
    "\n",
    "The LangGraph API [supports editing graph state](https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_edit_state/#initial-invocation). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8925b632-512b-48e1-9220-61c06bfbf0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    raise Exception(\"Unfortunately LangGraph Studio is currently not supported on Google Colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "079c2ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_sdk import get_client\n",
    "\n",
    "# This is the URL of the local development server\n",
    "#URL = \"http://127.0.0.1:2024\"\n",
    "URL = \"http://localhost:2024\"\n",
    "client = get_client(url=URL)\n",
    "\n",
    "# Search all hosted graphs\n",
    "assistants = await client.assistants.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc616d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'assistant_id': '6f6fce9a-b777-529d-9699-dd340ddec86c',\n",
       "  'graph_id': 'dynamic_breakpoints',\n",
       "  'config': {},\n",
       "  'metadata': {'created_by': 'system'},\n",
       "  'name': 'dynamic_breakpoints',\n",
       "  'created_at': '2025-05-18T14:26:48.148326+00:00',\n",
       "  'updated_at': '2025-05-18T14:26:48.148326+00:00',\n",
       "  'version': 1,\n",
       "  'description': None},\n",
       " {'assistant_id': 'fe096781-5601-53d2-b2f6-0d3403f7e9ca',\n",
       "  'graph_id': 'agent',\n",
       "  'config': {},\n",
       "  'metadata': {'created_by': 'system'},\n",
       "  'name': 'agent',\n",
       "  'created_at': '2025-05-18T14:26:48.145604+00:00',\n",
       "  'updated_at': '2025-05-18T14:26:48.145604+00:00',\n",
       "  'version': 1,\n",
       "  'description': None}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assistants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d15af9e-0e86-41e3-a5ba-ee2a4aa08a32",
   "metadata": {},
   "source": [
    "Let's [stream `values`](https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_values/), like before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63e3096f-5429-4d3c-8de2-2bddf7266ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StreamPart(event='metadata', data={'run_id': '1f0340e0-943f-68ee-8911-6c7c2be3fbdb', 'attempt': 1})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '986d2340-5337-42b1-8cf8-6e607d622f4a', 'example': False}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '986d2340-5337-42b1-8cf8-6e607d622f4a', 'example': False}, {'content': [{'id': 'toolu_01CarHKyYNdEyzceU2ELLcYB', 'input': {}, 'name': 'multiply', 'type': 'tool_use', 'index': 0, 'partial_json': '{\"a\": 2, \"b\": 3}'}], 'additional_kwargs': {}, 'response_metadata': {'model_name': 'claude-3-haiku-20240307', 'stop_reason': 'tool_use', 'stop_sequence': None}, 'type': 'ai', 'name': None, 'id': 'run--a522c6b0-9eda-4665-b237-2901a5c2ccf4-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'toolu_01CarHKyYNdEyzceU2ELLcYB', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 532, 'output_tokens': 72, 'total_tokens': 604, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '986d2340-5337-42b1-8cf8-6e607d622f4a', 'example': False}, {'content': [{'id': 'toolu_01CarHKyYNdEyzceU2ELLcYB', 'input': {}, 'name': 'multiply', 'type': 'tool_use', 'index': 0, 'partial_json': '{\"a\": 2, \"b\": 3}'}], 'additional_kwargs': {}, 'response_metadata': {'model_name': 'claude-3-haiku-20240307', 'stop_reason': 'tool_use', 'stop_sequence': None}, 'type': 'ai', 'name': None, 'id': 'run--a522c6b0-9eda-4665-b237-2901a5c2ccf4-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'toolu_01CarHKyYNdEyzceU2ELLcYB', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 532, 'output_tokens': 72, 'total_tokens': 604, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}}, {'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '1469fb11-fcc4-4652-a901-d506804fc4c9', 'tool_call_id': 'toolu_01CarHKyYNdEyzceU2ELLcYB', 'artifact': None, 'status': 'success'}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '986d2340-5337-42b1-8cf8-6e607d622f4a', 'example': False}, {'content': [{'id': 'toolu_01CarHKyYNdEyzceU2ELLcYB', 'input': {}, 'name': 'multiply', 'type': 'tool_use', 'index': 0, 'partial_json': '{\"a\": 2, \"b\": 3}'}], 'additional_kwargs': {}, 'response_metadata': {'model_name': 'claude-3-haiku-20240307', 'stop_reason': 'tool_use', 'stop_sequence': None}, 'type': 'ai', 'name': None, 'id': 'run--a522c6b0-9eda-4665-b237-2901a5c2ccf4-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'toolu_01CarHKyYNdEyzceU2ELLcYB', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 532, 'output_tokens': 72, 'total_tokens': 604, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}}, {'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '1469fb11-fcc4-4652-a901-d506804fc4c9', 'tool_call_id': 'toolu_01CarHKyYNdEyzceU2ELLcYB', 'artifact': None, 'status': 'success'}, {'content': [{'text': 'The result of multiplying 2 and 3 is 6.', 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'model_name': 'claude-3-haiku-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None}, 'type': 'ai', 'name': None, 'id': 'run--1ec134ea-91ec-4f7d-81ac-2f7d88f473e1-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 613, 'output_tokens': 22, 'total_tokens': 635, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}}]})\n"
     ]
    }
   ],
   "source": [
    "# Create a new thread\n",
    "thread = await client.threads.create()\n",
    "# Input message\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], \n",
    "                                      assistant_id=\"agent\", \n",
    "                                      input={\"messages\": [input_message]}, \n",
    "                                      stream_mode=\"values\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556dc7fd-1cae-404f-816a-f13d772b3b14",
   "metadata": {},
   "source": [
    "The streamed objects have: \n",
    "\n",
    "* `event`: Type\n",
    "* `data`: State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48baf846",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.set_printoptions(linewidth=100)\n",
    "pd.set_option('display.max_columns', 50) \n",
    "pd.set_option('display.width', 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57b735aa-139c-45a3-a850-63519c0004f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "content='Multiply 2 and 3' additional_kwargs={} response_metadata={} id='d9c78a39-3b07-49be-aa9b-823ebb1ee3c9'\n",
      "=========================\n",
      "content=[{'id': 'toolu_019i9zF5UmenbgGQjYQPaKgK', 'input': {}, 'name': 'multiply', 'type': 'tool_use', 'index': 0, 'partial_json': '{\"a\": 2, \"b\": 3}'}] additional_kwargs={'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 532, 'output_tokens': 72, 'total_tokens': 604, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}} response_metadata={'model_name': 'claude-3-haiku-20240307', 'stop_reason': 'tool_use', 'stop_sequence': None} id='run--2df475e5-c433-4582-87dc-647c9573f733-0' tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'toolu_019i9zF5UmenbgGQjYQPaKgK', 'type': 'tool_call'}]\n",
      "=========================\n",
      "content='6' name='multiply' id='bcaaab01-0048-46e6-bdf8-3b3976fcd4fd' tool_call_id='toolu_019i9zF5UmenbgGQjYQPaKgK'\n",
      "=========================\n",
      "content=[{'text': 'The result of multiplying 2 and 3 is 6.', 'type': 'text', 'index': 0}] additional_kwargs={'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 613, 'output_tokens': 22, 'total_tokens': 635, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}} response_metadata={'model_name': 'claude-3-haiku-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None} id='run--5cde0a41-02bd-4c79-8210-a68feab8d920-0'\n",
      "=========================\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import convert_to_messages\n",
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], assistant_id=\"agent\", input={\"messages\": [input_message]}, stream_mode=\"values\"):\n",
    "    messages = event.data.get('messages',None)\n",
    "    if messages:\n",
    "        #convert_to_messages is a function that converts the messages to a list of messages\n",
    "        # This is useful for debugging and understanding the messages\n",
    "        print(convert_to_messages(messages)[-1])\n",
    "    print('='*25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a555d186-27be-4ddf-934c-895a3105035d",
   "metadata": {},
   "source": [
    "### There are some new streaming mode that are only supported via the API.\n",
    "\n",
    "For example, we can [use `messages` mode](https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_messages/) to better handle the above case!\n",
    "\n",
    "This mode currently assumes that you have a `messages` key in your graph, which is a list of messages.\n",
    "\n",
    "All events emitted using `messages` mode have two attributes:\n",
    "\n",
    "* `event`: This is the name of the event\n",
    "* `data`: This is data associated with the event\n",
    "\n",
    "\n",
    "\n",
    "##### NOTE:  if the LLM you want to use is not implemented / configured as part of Langchain chat model interface, you can still stream the data from the LLM API. Please reference this doucmentation for details on how to implement custom message streaming from non langgraph configured LLMs: https://langchain-ai.github.io/langgraph/how-tos/streaming/#use-with-any-llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "4abd91f6-63c0-41ee-9988-7c8248b88a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVENT TYPE: metadata\n",
      "METADATA KEYS: ['count', 'data', 'event', 'index']\n",
      "METADATA DATA KEYS: ['run_id', 'attempt']\n",
      "Run ID: 1f034da3-d820-6bc4-9c27-8abfa5b076d1\n",
      "Attempt: 1\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "EVENT TYPE: messages/metadata\n",
      "EVENT KEYS: ['count', 'data', 'event', 'index']\n",
      "\n",
      "\n",
      "\u001b[1mmessages/metadata\u001b[0m has the following keys: ['run--bff36e6a-5a58-4a8c-a685-2aadc24df42e']\n",
      "\n",
      "\n",
      " The values for each parent key ['run--bff36e6a-5a58-4a8c-a685-2aadc24df42e'] is a nested dictionary with the following keys: ['metadata']\n",
      "\n",
      "\n",
      "\u001b[1m  Metadata child dictionary contains following metadata(printing keys): \u001b[0m ['created_by', 'graph_id', 'assistant_id', 'run_attempt', 'langgraph_version', 'langgraph_plan', 'langgraph_host', 'langgraph_api_url', 'user-agent', 'x-request-id', 'langgraph_auth_user_id', 'langgraph_request_id', 'run_id', 'thread_id', 'user_id', 'langgraph_step', 'langgraph_node', 'langgraph_triggers', 'langgraph_path', 'langgraph_checkpoint_ns', 'checkpoint_ns', 'ls_provider', 'ls_model_name', 'ls_model_type', 'ls_temperature', 'ls_max_tokens']\n",
      "\n",
      "\n",
      "\n",
      " \u001b[1m  metadata child dictionary @ step \u001b[0m\n",
      "    parent key: run--bff36e6a-5a58-4a8c-a685-2aadc24df42e -> child key: metadata\n",
      "\n",
      "\n",
      "  created_by -> system\n",
      "  graph_id -> agent\n",
      "  assistant_id -> fe096781-5601-53d2-b2f6-0d3403f7e9ca\n",
      "  run_attempt -> 1\n",
      "  langgraph_version -> 0.4.3\n",
      "  langgraph_plan -> developer\n",
      "  langgraph_host -> self-hosted\n",
      "  langgraph_api_url -> http://127.0.0.1:2024\n",
      "  user-agent -> langgraph-sdk-py/0.1.66\n",
      "  x-request-id -> 6068569c-c662-4b24-a349-cfb399644cdf\n",
      "  langgraph_auth_user_id -> \n",
      "  langgraph_request_id -> 6068569c-c662-4b24-a349-cfb399644cdf\n",
      "  run_id -> 1f034da3-d820-6bc4-9c27-8abfa5b076d1\n",
      "  thread_id -> 2b18df98-dc16-457c-a7a8-4ad24e2ee1fd\n",
      "  user_id -> \n",
      "  langgraph_step -> 1\n",
      "  langgraph_node -> assistant\n",
      "  langgraph_triggers -> ['branch:to:assistant']\n",
      "  langgraph_path -> ['__pregel_pull', 'assistant']\n",
      "  langgraph_checkpoint_ns -> assistant:3870e428-1183-c80c-10f9-b878f30c8a87\n",
      "  checkpoint_ns -> assistant:3870e428-1183-c80c-10f9-b878f30c8a87\n",
      "  ls_provider -> anthropic\n",
      "  ls_model_name -> claude-3-haiku-20240307\n",
      "  ls_model_type -> chat\n",
      "  ls_temperature -> 0.0\n",
      "  ls_max_tokens -> 4000\n",
      "--------------------------------------------------\n",
      "EVENT TYPE: messages/partial\n",
      "TOTAL OCCURANCES OF MESSAGES/PARTIAL: 1\n",
      "RESPONSE METADATA (FINISH REASON) - N/A\n",
      "--------------------------------------------------\n",
      "EVENT TYPE: messages/partial\n",
      "TOTAL OCCURANCES OF MESSAGES/PARTIAL: 2\n",
      "TOOL CALLS: Tool Call ID: toolu_01CahgvX2L6xkFfDwZyfDMYm                 , Function: multiply                 , Arguments: {}\n",
      "RESPONSE METADATA (FINISH REASON) - N/A\n",
      "--------------------------------------------------\n",
      "EVENT TYPE: messages/partial\n",
      "TOTAL OCCURANCES OF MESSAGES/PARTIAL: 3\n",
      "TOOL CALLS: Tool Call ID: toolu_01CahgvX2L6xkFfDwZyfDMYm                 , Function: multiply                 , Arguments: {}\n",
      "RESPONSE METADATA (FINISH REASON) - N/A\n",
      "--------------------------------------------------\n",
      "EVENT TYPE: messages/partial\n",
      "TOTAL OCCURANCES OF MESSAGES/PARTIAL: 4\n",
      "TOOL CALLS: Tool Call ID: toolu_01CahgvX2L6xkFfDwZyfDMYm                 , Function: multiply                 , Arguments: {'a': 2}\n",
      "RESPONSE METADATA (FINISH REASON) - N/A\n",
      "--------------------------------------------------\n",
      "EVENT TYPE: messages/partial\n",
      "TOTAL OCCURANCES OF MESSAGES/PARTIAL: 5\n",
      "TOOL CALLS: Tool Call ID: toolu_01CahgvX2L6xkFfDwZyfDMYm                 , Function: multiply                 , Arguments: {'a': 2, 'b': 3}\n",
      "RESPONSE METADATA (FINISH REASON) - N/A\n",
      "--------------------------------------------------\n",
      "EVENT TYPE: messages/partial\n",
      "TOTAL OCCURANCES OF MESSAGES/PARTIAL: 6\n",
      "TOOL CALLS: Tool Call ID: toolu_01CahgvX2L6xkFfDwZyfDMYm                 , Function: multiply                 , Arguments: {'a': 2, 'b': 3}\n",
      "RESPONSE METADATA (FINISH REASON) - tool_use\n",
      "--------------------------------------------------\n",
      "EVENT TYPE: messages/metadata\n",
      "\n",
      " \u001b[1m  metadata child dictionary @ step \u001b[0m\n",
      "    parent key: 9bf21b15-ff59-4b75-bb2a-e3e54eb156ff -> child key: metadata\n",
      "\n",
      "\n",
      "  created_by -> system\n",
      "  graph_id -> agent\n",
      "  assistant_id -> fe096781-5601-53d2-b2f6-0d3403f7e9ca\n",
      "  run_attempt -> 1\n",
      "  langgraph_version -> 0.4.3\n",
      "  langgraph_plan -> developer\n",
      "  langgraph_host -> self-hosted\n",
      "  langgraph_api_url -> http://127.0.0.1:2024\n",
      "  user-agent -> langgraph-sdk-py/0.1.66\n",
      "  x-request-id -> 6068569c-c662-4b24-a349-cfb399644cdf\n",
      "  langgraph_auth_user_id -> \n",
      "  langgraph_request_id -> 6068569c-c662-4b24-a349-cfb399644cdf\n",
      "  run_id -> 1f034da3-d820-6bc4-9c27-8abfa5b076d1\n",
      "  thread_id -> 2b18df98-dc16-457c-a7a8-4ad24e2ee1fd\n",
      "  user_id -> \n",
      "  langgraph_step -> 2\n",
      "  langgraph_node -> tools\n",
      "  langgraph_triggers -> ['branch:to:tools']\n",
      "  langgraph_path -> ['__pregel_pull', 'tools']\n",
      "  langgraph_checkpoint_ns -> tools:54806bdc-42cd-2fb9-1b18-f749cf5cef34\n",
      "--------------------------------------------------\n",
      "EVENT TYPE: messages/complete\n",
      "EVENT TYPE: messages/metadata\n",
      "\n",
      " \u001b[1m  metadata child dictionary @ step \u001b[0m\n",
      "    parent key: run--ac2fd2fb-db9b-4e08-9ee8-f62791b669f1 -> child key: metadata\n",
      "\n",
      "\n",
      "  created_by -> system\n",
      "  graph_id -> agent\n",
      "  assistant_id -> fe096781-5601-53d2-b2f6-0d3403f7e9ca\n",
      "  run_attempt -> 1\n",
      "  langgraph_version -> 0.4.3\n",
      "  langgraph_plan -> developer\n",
      "  langgraph_host -> self-hosted\n",
      "  langgraph_api_url -> http://127.0.0.1:2024\n",
      "  user-agent -> langgraph-sdk-py/0.1.66\n",
      "  x-request-id -> 6068569c-c662-4b24-a349-cfb399644cdf\n",
      "  langgraph_auth_user_id -> \n",
      "  langgraph_request_id -> 6068569c-c662-4b24-a349-cfb399644cdf\n",
      "  run_id -> 1f034da3-d820-6bc4-9c27-8abfa5b076d1\n",
      "  thread_id -> 2b18df98-dc16-457c-a7a8-4ad24e2ee1fd\n",
      "  user_id -> \n",
      "  langgraph_step -> 3\n",
      "  langgraph_node -> assistant\n",
      "  langgraph_triggers -> ['branch:to:assistant']\n",
      "  langgraph_path -> ['__pregel_pull', 'assistant']\n",
      "  langgraph_checkpoint_ns -> assistant:6a1c1faf-8853-5b69-81c3-f833b0925cf7\n",
      "  checkpoint_ns -> assistant:6a1c1faf-8853-5b69-81c3-f833b0925cf7\n",
      "  ls_provider -> anthropic\n",
      "  ls_model_name -> claude-3-haiku-20240307\n",
      "  ls_model_type -> chat\n",
      "  ls_temperature -> 0.0\n",
      "  ls_max_tokens -> 4000\n",
      "--------------------------------------------------\n",
      "EVENT TYPE: messages/partial\n",
      "TOTAL OCCURANCES OF MESSAGES/PARTIAL: 7\n",
      "RESPONSE METADATA (FINISH REASON) - N/A\n",
      "--------------------------------------------------\n",
      "EVENT TYPE: messages/partial\n",
      "TOTAL OCCURANCES OF MESSAGES/PARTIAL: 8\n",
      "AI: The\n",
      "RESPONSE METADATA (FINISH REASON) - N/A\n",
      "--------------------------------------------------\n",
      "EVENT TYPE: messages/partial\n",
      "TOTAL OCCURANCES OF MESSAGES/PARTIAL: 9\n",
      "AI: The result of multiplying\n",
      "RESPONSE METADATA (FINISH REASON) - N/A\n",
      "--------------------------------------------------\n",
      "EVENT TYPE: messages/partial\n",
      "TOTAL OCCURANCES OF MESSAGES/PARTIAL: 10\n",
      "AI: The result of multiplying 2 and 3 is\n",
      "RESPONSE METADATA (FINISH REASON) - N/A\n",
      "--------------------------------------------------\n",
      "EVENT TYPE: messages/partial\n",
      "TOTAL OCCURANCES OF MESSAGES/PARTIAL: 11\n",
      "AI: The result of multiplying 2 and 3 is 6.\n",
      "RESPONSE METADATA (FINISH REASON) - N/A\n",
      "--------------------------------------------------\n",
      "EVENT TYPE: messages/partial\n",
      "TOTAL OCCURANCES OF MESSAGES/PARTIAL: 12\n",
      "AI: The result of multiplying 2 and 3 is 6.\n",
      "RESPONSE METADATA (FINISH REASON) - end_turn\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def format_tool_calls(tool_calls):\n",
    "    \"\"\"\n",
    "    Format a list of tool calls into a readable string.\n",
    "\n",
    "    Args:\n",
    "        tool_calls (list): A list of dictionaries, each representing a tool call.\n",
    "            Each dictionary should have 'id', 'name', and 'args' keys.\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string of tool calls, or \"No tool calls\" if the list is empty.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if tool_calls:\n",
    "        formatted_calls = []\n",
    "        for call in tool_calls:\n",
    "            formatted_calls.append(\n",
    "                f\"Tool Call ID: {call['id']} \\\n",
    "                , Function: {call['name']} \\\n",
    "                , Arguments: {call['args']}\"\n",
    "            )\n",
    "        return \"\\n\".join(formatted_calls)\n",
    "    return \"No tool calls\"\n",
    "\n",
    "# Create a new thread\n",
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "\n",
    "\n",
    "eventlist  = {}\n",
    "\n",
    "async for event in client.runs.stream(\n",
    "    \n",
    "    #ID of the conversation thread\n",
    "    thread[\"thread_id\"]\n",
    "\n",
    "    #Name of the assistant / agent as specified in the name of the file containing the graph logic: /home/zjc1002/Mounts/code/langgraph_projects/langchain-academy/module-3/studio/agent.py\n",
    "    , assistant_id=\"agent\"\n",
    "\n",
    "    #Input message to the assistant\n",
    "    , input={\"messages\": [input_message]}\n",
    "\n",
    "    #Stream mode to use. This can be \"values\" or \"messages\"\n",
    "    #NOTE: values is the default mode and will return the values of the messages, 'messages' will return the messages as they are generated\n",
    "    , stream_mode=\"messages\"):\n",
    "\n",
    "    #count total number of each type of event as they are streamed \n",
    "    eventlist[event.event] = eventlist.get(event.event,0) + 1\n",
    "\n",
    "    print(f\"EVENT TYPE: {event.event}\") \n",
    "    \n",
    "    # MEATADATA EVENT \n",
    "    #print the event type and the number of times it has been streamed\n",
    "    if event.event == \"metadata\":\n",
    "\n",
    "        #event is a dictionary that contains the metadata of the event\n",
    "        #un-usable keys: count(), index()\n",
    "        #usable keys: event(), data()\n",
    "        print(f\"METADATA KEYS: {[v for v in dir(event) if not (v.startswith('_') or v.endswith('_'))]}\")\n",
    "        print(f\"METADATA DATA KEYS: {[v for v in event.data.keys() if not (v.startswith('_') or v.endswith('_'))]}\")\n",
    "        print(f\"Run ID: {event.data['run_id']}\")\n",
    "        print(f\"Attempt: {event.data['attempt']}\")\n",
    "        print('\\n')\n",
    "        print(\"-\" * 50)\n",
    "    # MESSAGE METADATA EVENT\n",
    "    #messages/metatadata is a dic that contains the metadata of the messages\n",
    "    elif event.event == \"messages/metadata\" :\n",
    "\n",
    "        if eventlist[event.event] == 1:\n",
    "            print(f\"EVENT KEYS: {[v for v in dir(event) if not (v.startswith('_') or v.endswith('_'))]}\")        \n",
    "\n",
    "\n",
    "            # traversing the keys of the messages/metadata dictionary\n",
    "            # Using ANSI escape codes for bold text\n",
    "            print('\\n')\n",
    "            print(f\"\\033[1m{event.event}\\033[0m has the following keys: {[x for x in event.data.keys()]}\")  \n",
    "            print('\\n')\n",
    "            #each nested dictionary contains the metadata of the messages contained within the metadata key (its the only key)\n",
    "            print(f\" The values for each parent key {[x for x in event.data.keys()]} is a nested dictionary with the following keys: {[x for x in event.data[next(iter(event.data))].keys()]}\")\n",
    "            print('\\n')\n",
    "            print(f\"\\033[1m  Metadata child dictionary contains following metadata(printing keys): \\033[0m {[x for x in event.data[next(iter(event.data))][next(iter(event.data[next(iter(event.data))]))].keys()]}\")\n",
    "            print('\\n')\n",
    "\n",
    "        print(f\"\\n \\033[1m  metadata child dictionary @ step \\033[0m\")\n",
    "        \n",
    "        # For a nested dictionary structure\n",
    "        for outer_key, inner_dict in event.data.items():\n",
    "\n",
    "            for inner_key, inner_value in inner_dict.items():\n",
    "                print(f\"    parent key: {outer_key} -> child key: {inner_key}\")\n",
    "                print(\"\\n\")\n",
    "\n",
    "                for k,v in inner_value.items():\n",
    "                    print(f\"  {k} -> {v}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "    #STREAMING TOKEN EVENT \n",
    "    elif event.event == \"messages/partial\" :\n",
    "        print(f\"TOTAL OCCURANCES OF {str(event.event).upper()}: {eventlist[event.event]}\")\n",
    "        \n",
    "        #messages/partial is a list of dictionaries that contains the metadata of the messages\n",
    "        for data_item in event.data:\n",
    "            if 'role' in data_item and data_item['role'] == 'user':\n",
    "                print(f\"Human: {data_item['content']}\") \n",
    "            else:\n",
    "                \n",
    "                # Extract relevant data from the event\n",
    "                tool_calls = data_item.get(\"tool_calls\", [])\n",
    "                invalid_tool_calls = data_item.get(\"invalid_tool_calls\", [])\n",
    "                content = data_item.get(\"content\", \"\")\n",
    "                response_metadata = data_item.get(\"response_metadata\", {})\n",
    "                \n",
    "                # Process the AI tokens being streamed if they exist\n",
    "                if ((content not in [\"\",[]])):\n",
    "                    if isinstance(content, list):\n",
    "\n",
    "                        # If content is a list, print each item\n",
    "                        for item in content:\n",
    "                            if 'text' in item: \n",
    "                                print(f\"AI: {item.get('text','NO TEXT')}\")\n",
    "\n",
    "                \n",
    "                if tool_calls:\n",
    "                    print(f\"TOOL CALLS: {format_tool_calls(tool_calls)}\")\n",
    "        \n",
    "                if invalid_tool_calls:\n",
    "                    print(\"INVALID TOOL CALLS:\")\n",
    "                    print(format_tool_calls(invalid_tool_calls))\n",
    "\n",
    "                if response_metadata:\n",
    "                    finish_reason = response_metadata.get(\"stop_reason\", \"N/A\")\n",
    "                    print(f\"RESPONSE METADATA (FINISH REASON) - {finish_reason}\")\n",
    "                    \n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "b6298d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'claude-3-haiku-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None}\n",
      "end_turn\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for _i in event.data:\n",
    "    print(_i['response_metadata'])\n",
    "    print(_i['response_metadata']['stop_reason'])\n",
    "    print(_i['response_metadata']['stop_sequence'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a1e0c8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata\n",
      "{'run_id': '1f034b12-d48a-6c24-8fec-ff6284084bd2', 'attempt': 1}\n",
      "messages/metadata\n",
      "{'run--c5e457ce-cf42-46ea-886f-6612e0141438': {'metadata': {'created_by': 'system', 'graph_id': 'agent', 'assistant_id': 'fe096781-5601-53d2-b2f6-0d3403f7e9ca', 'run_attempt': 1, 'langgraph_version': '0.4.3', 'langgraph_plan': 'developer', 'langgraph_host': 'self-hosted', 'langgraph_api_url': 'http://127.0.0.1:2024', 'user-agent': 'langgraph-sdk-py/0.1.66', 'x-request-id': '982a17c4-4136-4bd0-a8d3-c47053743b3e', 'langgraph_auth_user_id': '', 'langgraph_request_id': '982a17c4-4136-4bd0-a8d3-c47053743b3e', 'run_id': '1f034b12-d48a-6c24-8fec-ff6284084bd2', 'thread_id': 'af1c77b5-73a0-4e1b-b4f4-33fd106f8d5b', 'user_id': '', 'langgraph_step': 6, 'langgraph_node': 'assistant', 'langgraph_triggers': ['branch:to:assistant'], 'langgraph_path': ['__pregel_pull', 'assistant'], 'langgraph_checkpoint_ns': 'assistant:cc7499bf-c779-f089-8e1b-16594635a153', 'checkpoint_ns': 'assistant:cc7499bf-c779-f089-8e1b-16594635a153', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 4000}}}\n",
      "messages/partial\n",
      "[{'content': [], 'additional_kwargs': {}, 'response_metadata': {'model_name': 'claude-3-haiku-20240307'}, 'type': 'ai', 'name': None, 'id': 'run--c5e457ce-cf42-46ea-886f-6612e0141438', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 644, 'output_tokens': 1, 'total_tokens': 645, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}}]\n",
      "messages/partial\n",
      "[{'content': [{'id': 'toolu_01RoWf1fE5UnMagWcP83umTS', 'input': {}, 'name': 'multiply', 'type': 'tool_use', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'model_name': 'claude-3-haiku-20240307'}, 'type': 'ai', 'name': None, 'id': 'run--c5e457ce-cf42-46ea-886f-6612e0141438', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {}, 'id': 'toolu_01RoWf1fE5UnMagWcP83umTS', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 644, 'output_tokens': 1, 'total_tokens': 645, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}}]\n",
      "messages/partial\n",
      "[{'content': [{'id': 'toolu_01RoWf1fE5UnMagWcP83umTS', 'input': {}, 'name': 'multiply', 'type': 'tool_use', 'index': 0, 'partial_json': ''}], 'additional_kwargs': {}, 'response_metadata': {'model_name': 'claude-3-haiku-20240307'}, 'type': 'ai', 'name': None, 'id': 'run--c5e457ce-cf42-46ea-886f-6612e0141438', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {}, 'id': 'toolu_01RoWf1fE5UnMagWcP83umTS', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 644, 'output_tokens': 1, 'total_tokens': 645, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}}]\n",
      "messages/partial\n",
      "[{'content': [{'id': 'toolu_01RoWf1fE5UnMagWcP83umTS', 'input': {}, 'name': 'multiply', 'type': 'tool_use', 'index': 0, 'partial_json': '{\"a\": 2'}], 'additional_kwargs': {}, 'response_metadata': {'model_name': 'claude-3-haiku-20240307'}, 'type': 'ai', 'name': None, 'id': 'run--c5e457ce-cf42-46ea-886f-6612e0141438', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2}, 'id': 'toolu_01RoWf1fE5UnMagWcP83umTS', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 644, 'output_tokens': 1, 'total_tokens': 645, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}}]\n",
      "messages/partial\n",
      "[{'content': [{'id': 'toolu_01RoWf1fE5UnMagWcP83umTS', 'input': {}, 'name': 'multiply', 'type': 'tool_use', 'index': 0, 'partial_json': '{\"a\": 2, \"b'}], 'additional_kwargs': {}, 'response_metadata': {'model_name': 'claude-3-haiku-20240307'}, 'type': 'ai', 'name': None, 'id': 'run--c5e457ce-cf42-46ea-886f-6612e0141438', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2}, 'id': 'toolu_01RoWf1fE5UnMagWcP83umTS', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 644, 'output_tokens': 1, 'total_tokens': 645, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}}]\n",
      "messages/partial\n",
      "[{'content': [{'id': 'toolu_01RoWf1fE5UnMagWcP83umTS', 'input': {}, 'name': 'multiply', 'type': 'tool_use', 'index': 0, 'partial_json': '{\"a\": 2, \"b\": 3}'}], 'additional_kwargs': {}, 'response_metadata': {'model_name': 'claude-3-haiku-20240307'}, 'type': 'ai', 'name': None, 'id': 'run--c5e457ce-cf42-46ea-886f-6612e0141438', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'toolu_01RoWf1fE5UnMagWcP83umTS', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 644, 'output_tokens': 1, 'total_tokens': 645, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}}]\n",
      "messages/partial\n",
      "[{'content': [{'id': 'toolu_01RoWf1fE5UnMagWcP83umTS', 'input': {}, 'name': 'multiply', 'type': 'tool_use', 'index': 0, 'partial_json': '{\"a\": 2, \"b\": 3}'}], 'additional_kwargs': {}, 'response_metadata': {'model_name': 'claude-3-haiku-20240307', 'stop_reason': 'tool_use', 'stop_sequence': None}, 'type': 'ai', 'name': None, 'id': 'run--c5e457ce-cf42-46ea-886f-6612e0141438', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'toolu_01RoWf1fE5UnMagWcP83umTS', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 644, 'output_tokens': 69, 'total_tokens': 713, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}}]\n",
      "messages/metadata\n",
      "{'289ce04a-1007-45d4-96d1-b9d4b0b44ba5': {'metadata': {'created_by': 'system', 'graph_id': 'agent', 'assistant_id': 'fe096781-5601-53d2-b2f6-0d3403f7e9ca', 'run_attempt': 1, 'langgraph_version': '0.4.3', 'langgraph_plan': 'developer', 'langgraph_host': 'self-hosted', 'langgraph_api_url': 'http://127.0.0.1:2024', 'user-agent': 'langgraph-sdk-py/0.1.66', 'x-request-id': '982a17c4-4136-4bd0-a8d3-c47053743b3e', 'langgraph_auth_user_id': '', 'langgraph_request_id': '982a17c4-4136-4bd0-a8d3-c47053743b3e', 'run_id': '1f034b12-d48a-6c24-8fec-ff6284084bd2', 'thread_id': 'af1c77b5-73a0-4e1b-b4f4-33fd106f8d5b', 'user_id': '', 'langgraph_step': 7, 'langgraph_node': 'tools', 'langgraph_triggers': ['branch:to:tools'], 'langgraph_path': ['__pregel_pull', 'tools'], 'langgraph_checkpoint_ns': 'tools:2226d681-9f61-747e-dc94-406a617046cc'}}}\n",
      "messages/complete\n",
      "[{'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '289ce04a-1007-45d4-96d1-b9d4b0b44ba5', 'tool_call_id': 'toolu_01RoWf1fE5UnMagWcP83umTS', 'artifact': None, 'status': 'success'}]\n",
      "messages/metadata\n",
      "{'run--5ea77d4f-3825-4f03-a48f-291637502f59': {'metadata': {'created_by': 'system', 'graph_id': 'agent', 'assistant_id': 'fe096781-5601-53d2-b2f6-0d3403f7e9ca', 'run_attempt': 1, 'langgraph_version': '0.4.3', 'langgraph_plan': 'developer', 'langgraph_host': 'self-hosted', 'langgraph_api_url': 'http://127.0.0.1:2024', 'user-agent': 'langgraph-sdk-py/0.1.66', 'x-request-id': '982a17c4-4136-4bd0-a8d3-c47053743b3e', 'langgraph_auth_user_id': '', 'langgraph_request_id': '982a17c4-4136-4bd0-a8d3-c47053743b3e', 'run_id': '1f034b12-d48a-6c24-8fec-ff6284084bd2', 'thread_id': 'af1c77b5-73a0-4e1b-b4f4-33fd106f8d5b', 'user_id': '', 'langgraph_step': 8, 'langgraph_node': 'assistant', 'langgraph_triggers': ['branch:to:assistant'], 'langgraph_path': ['__pregel_pull', 'assistant'], 'langgraph_checkpoint_ns': 'assistant:9b3980de-ad1a-fbe2-9a50-d368ee3fbca0', 'checkpoint_ns': 'assistant:9b3980de-ad1a-fbe2-9a50-d368ee3fbca0', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 4000}}}\n",
      "messages/partial\n",
      "[{'content': [], 'additional_kwargs': {}, 'response_metadata': {'model_name': 'claude-3-haiku-20240307'}, 'type': 'ai', 'name': None, 'id': 'run--5ea77d4f-3825-4f03-a48f-291637502f59', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 725, 'output_tokens': 4, 'total_tokens': 729, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}}]\n",
      "messages/partial\n",
      "[{'content': [{'text': 'The result of', 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'model_name': 'claude-3-haiku-20240307'}, 'type': 'ai', 'name': None, 'id': 'run--5ea77d4f-3825-4f03-a48f-291637502f59', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 725, 'output_tokens': 4, 'total_tokens': 729, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}}]\n",
      "messages/partial\n",
      "[{'content': [{'text': 'The result of multiplying 2', 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'model_name': 'claude-3-haiku-20240307'}, 'type': 'ai', 'name': None, 'id': 'run--5ea77d4f-3825-4f03-a48f-291637502f59', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 725, 'output_tokens': 4, 'total_tokens': 729, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}}]\n",
      "messages/partial\n",
      "[{'content': [{'text': 'The result of multiplying 2 and 3 is 6', 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'model_name': 'claude-3-haiku-20240307'}, 'type': 'ai', 'name': None, 'id': 'run--5ea77d4f-3825-4f03-a48f-291637502f59', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 725, 'output_tokens': 4, 'total_tokens': 729, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}}]\n",
      "messages/partial\n",
      "[{'content': [{'text': 'The result of multiplying 2 and 3 is 6.', 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'model_name': 'claude-3-haiku-20240307'}, 'type': 'ai', 'name': None, 'id': 'run--5ea77d4f-3825-4f03-a48f-291637502f59', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 725, 'output_tokens': 4, 'total_tokens': 729, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}}]\n",
      "messages/partial\n",
      "[{'content': [{'text': 'The result of multiplying 2 and 3 is 6.', 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'model_name': 'claude-3-haiku-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None}, 'type': 'ai', 'name': None, 'id': 'run--5ea77d4f-3825-4f03-a48f-291637502f59', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 725, 'output_tokens': 24, 'total_tokens': 749, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}}]\n"
     ]
    }
   ],
   "source": [
    "async for event in client.runs.stream(thread[\"thread_id\"], \n",
    "                                      assistant_id=\"agent\", \n",
    "                                      input={\"messages\": [input_message]}, \n",
    "                                      stream_mode=\"messages\"):\n",
    "    print(event.event)\n",
    "    print(event.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60887f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8de2f1ea-b232-43fc-af7a-320efce83381",
   "metadata": {},
   "source": [
    "We can see a few events: \n",
    "\n",
    "* `metadata`: metadata about the run\n",
    "* `messages/complete`: fully formed message \n",
    "* `messages/partial`: chat model tokens\n",
    "\n",
    "You can dig further into the types [here](https://langchain-ai.github.io/langgraph/cloud/concepts/api/#modemessages).\n",
    "\n",
    "Now, let's show how to stream these messages. \n",
    "\n",
    "We'll define a helper function for better formatting of the tool calls in messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "50a85e16-6e3f-4f14-bcf9-8889a762f522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata: Run ID - 1f0340ee-6045-6c1b-89ec-28655dc0848b\n",
      "--------------------------------------------------\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "AI: [{'id': 'toolu_01SQir834n8Q4nZASUkGtP9c', 'input': {}, 'name': 'multiply', 'type': 'tool_use', 'index': 0}]\n",
      "Tool Calls:\n",
      "Tool Call ID: toolu_01SQir834n8Q4nZASUkGtP9c                 , Function: multiply                 , Arguments: {}\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "AI: [{'id': 'toolu_01SQir834n8Q4nZASUkGtP9c', 'input': {}, 'name': 'multiply', 'type': 'tool_use', 'index': 0, 'partial_json': ''}]\n",
      "Tool Calls:\n",
      "Tool Call ID: toolu_01SQir834n8Q4nZASUkGtP9c                 , Function: multiply                 , Arguments: {}\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "AI: [{'id': 'toolu_01SQir834n8Q4nZASUkGtP9c', 'input': {}, 'name': 'multiply', 'type': 'tool_use', 'index': 0, 'partial_json': '{\"a\": '}]\n",
      "Tool Calls:\n",
      "Tool Call ID: toolu_01SQir834n8Q4nZASUkGtP9c                 , Function: multiply                 , Arguments: {}\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "AI: [{'id': 'toolu_01SQir834n8Q4nZASUkGtP9c', 'input': {}, 'name': 'multiply', 'type': 'tool_use', 'index': 0, 'partial_json': '{\"a\": 2'}]\n",
      "Tool Calls:\n",
      "Tool Call ID: toolu_01SQir834n8Q4nZASUkGtP9c                 , Function: multiply                 , Arguments: {'a': 2}\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "AI: [{'id': 'toolu_01SQir834n8Q4nZASUkGtP9c', 'input': {}, 'name': 'multiply', 'type': 'tool_use', 'index': 0, 'partial_json': '{\"a\": 2, \"b\": 3}'}]\n",
      "Tool Calls:\n",
      "Tool Call ID: toolu_01SQir834n8Q4nZASUkGtP9c                 , Function: multiply                 , Arguments: {'a': 2, 'b': 3}\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "AI: [{'id': 'toolu_01SQir834n8Q4nZASUkGtP9c', 'input': {}, 'name': 'multiply', 'type': 'tool_use', 'index': 0, 'partial_json': '{\"a\": 2, \"b\": 3}'}]\n",
      "Tool Calls:\n",
      "Tool Call ID: toolu_01SQir834n8Q4nZASUkGtP9c                 , Function: multiply                 , Arguments: {'a': 2, 'b': 3}\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "AI: [{'text': 'The', 'type': 'text', 'index': 0}]\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "AI: [{'text': 'The result of multiplying 2 an', 'type': 'text', 'index': 0}]\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "AI: [{'text': 'The result of multiplying 2 and 3 is 6.', 'type': 'text', 'index': 0}]\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "AI: [{'text': 'The result of multiplying 2 and 3 is 6.', 'type': 'text', 'index': 0}]\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "\n",
    "def format_tool_calls(tool_calls):\n",
    "    \"\"\"\n",
    "    Format a list of tool calls into a readable string.\n",
    "\n",
    "    Args:\n",
    "        tool_calls (list): A list of dictionaries, each representing a tool call.\n",
    "            Each dictionary should have 'id', 'name', and 'args' keys.\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string of tool calls, or \"No tool calls\" if the list is empty.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if tool_calls:\n",
    "        formatted_calls = []\n",
    "        for call in tool_calls:\n",
    "            formatted_calls.append(\n",
    "                f\"Tool Call ID: {call['id']} \\\n",
    "                , Function: {call['name']} \\\n",
    "                , Arguments: {call['args']}\"\n",
    "            )\n",
    "        return \"\\n\".join(formatted_calls)\n",
    "    return \"No tool calls\"\n",
    "\n",
    "async for event in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    assistant_id=\"agent\",\n",
    "    input={\"messages\": [input_message]},\n",
    "    stream_mode=\"messages\",):\n",
    "    \n",
    "    # Handle metadata events\n",
    "    if event.event == \"metadata\":\n",
    "        print(f\"Metadata: Run ID - {event.data['run_id']}\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    # Handle partial message events\n",
    "    elif event.event == \"messages/partial\":\n",
    "        for data_item in event.data:\n",
    "            # Process user messages\n",
    "            if \"role\" in data_item and data_item[\"role\"] == \"user\":\n",
    "                print(f\"Human: {data_item['content']}\")\n",
    "            else:\n",
    "                # Extract relevant data from the event\n",
    "                tool_calls = data_item.get(\"tool_calls\", [])\n",
    "                invalid_tool_calls = data_item.get(\"invalid_tool_calls\", [])\n",
    "                content = data_item.get(\"content\", \"\")\n",
    "                response_metadata = data_item.get(\"response_metadata\", {})\n",
    "\n",
    "                if content:\n",
    "                    print(f\"AI: {content}\")\n",
    "\n",
    "                if tool_calls:\n",
    "                    print(\"Tool Calls:\")\n",
    "                    print(format_tool_calls(tool_calls))\n",
    "\n",
    "                if invalid_tool_calls:\n",
    "                    print(\"Invalid Tool Calls:\")\n",
    "                    print(format_tool_calls(invalid_tool_calls))\n",
    "\n",
    "                if response_metadata:\n",
    "                    finish_reason = response_metadata.get(\"finish_reason\", \"N/A\")\n",
    "                    print(f\"Response Metadata: Finish Reason - {finish_reason}\")\n",
    "                    \n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae885f8-102f-448a-9d68-8ded8d2bbd18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langy3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
